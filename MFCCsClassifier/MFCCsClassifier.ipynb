{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0398eec-5842-4ca8-b6ac-1c608701c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee4c7a5-bec0-46c4-ba87-c6a146c994b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = np.load(\"../preprocessing/MFCCs/MFCC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984cc5a9-043d-4989-b52c-0a7bc31bd3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = (MFCCs - np.nanmean(MFCCs))/np.nanstd(MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "571f061a-4c46-400d-a3d1-e81f8bca7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.49531220e+00 -7.49531220e+00 -7.49531220e+00 ... -2.28470204e+00\n",
      "  -2.28154364e+00 -2.46218506e+00]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  2.66772499e+00\n",
      "   2.75375372e+00  2.64647346e+00]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ... -3.14520361e-01\n",
      "  -2.91229857e-01 -4.12438540e-01]\n",
      " ...\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  3.09898681e-02\n",
      "   4.16713754e-03 -1.56268668e-03]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  5.42445234e-02\n",
      "   1.41780647e-01  9.51679247e-02]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  4.73457277e-02\n",
      "   6.71201664e-02  1.52584397e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(MFCCs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe39aa7-119e-4906-8fa8-eaae2615caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_songs = pd.read_csv(\"../Info/info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d86c1c-3986-4d19-91d8-6a0509686f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_songs = pd.read_csv(\"../preprocessing/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5920ce90-7409-4223-b87f-312d38dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_label = \"genre\"\n",
    "\n",
    "if select_label == \"genre\":\n",
    "    labels = label_songs[select_label].map({\"classical\":0, \"electronic\":1, \"pop\":2, \"rock\":3})\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28facf76-60bf-442b-81c6-6def82ec6277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df75dcd-3c43-453d-982e-81914596b266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Song length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Track ID  Song length\n",
       "0           1          600\n",
       "1          10          600\n",
       "2         100          600\n",
       "3          11          600\n",
       "4          12          600\n",
       "..        ...          ...\n",
       "395       395          600\n",
       "396       396          600\n",
       "397       397          600\n",
       "398       398          600\n",
       "399       399          600\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_songs = pd.DataFrame(info_songs[\"Track ID\"])\n",
    "length_songs[\"Song length\"] = info_songs[\"Duration\"]*10\n",
    "length_songs[\"Song length\"] = length_songs[\"Song length\"].astype(int)\n",
    "length_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53af9ef3-1908-49b4-9ab8-2e057cdb8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(length_songs)\n",
    "idx = np.random.permutation(n_data)\n",
    "length_songs = length_songs.reindex(idx)[\"Song length\"].to_numpy()\n",
    "MFCCs = MFCCs[idx, :, :]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5f3129-a9ba-4944-85a0-25085b6df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a47f5e-962e-4040-b8d7-488523b37cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_validation = 0.25\n",
    "n_test = int(fraction_validation*len(labels))\n",
    "n_train = len(labels) - n_test\n",
    "\n",
    "train_features, train_labels, train_length = MFCCs[:n_train], labels[:n_train], length_songs[:n_train]\n",
    "validation_features, validation_labels, validation_length = MFCCs[n_train:], labels[n_train:], length_songs[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b2156b-ce32-483b-afa3-96554f470f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels, train_length))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels, validation_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a856cae8-bd13-4456-80c0-47940da6a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#sample_size = (20, 50, 1)\n",
    "sample_size = (20, 100, 1)\n",
    "\n",
    "drop_out_rate = 0.2\n",
    "\n",
    "# very simple keras Sequential model\n",
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (1, 10), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.Conv2D(32, (1, 5), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(50, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93708a8d-dff3-4e19-84ba-0bd895d344af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 100, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 91, 16)        176       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 87, 32)        2592      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 87, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13760)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                688050    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 691,022\n",
      "Trainable params: 691,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5ee0abf-f165-4cb6-9bab-d6cfbaf91d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 20, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 48, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 46, 16)        1168      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 22, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 20, 8)          1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 9, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2900      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 5,392\n",
      "Trainable params: 5,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_size = (20, 50, 1)\n",
    "\n",
    "drop_out_rate = 0.4\n",
    "\n",
    "# very simple keras Sequential model\n",
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(8, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.Conv2D(16, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(input_tensor, output_tensor)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a5944b-7563-4fd0-abcd-1dfed65f94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 20, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 24, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 22, 32)         4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 11, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 10, 32)         2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 4, 16)          2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 10,132\n",
      "Trainable params: 10,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (1,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(1,2))(x)\n",
    "\n",
    "x = layers.Conv2D(16, (2,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(2*drop_out_rate)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(input_tensor, output_tensor)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66f45a25-2f54-413f-b3b0-832f9285ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_1\n",
    "#model = model_2\n",
    "#model = model_3\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a29b84-c1aa-43ba-8a8d-99db7d769475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_accordingly(input_tensor, labels, size=sample_size):\n",
    "\n",
    "    input_shape = (tf.shape(input_tensor).numpy())\n",
    "    \n",
    "    input_shape[1], input_shape[2] = size[0], size[1]\n",
    "    size = input_shape\n",
    "    \n",
    "    sliced_tensor = tf.image.random_crop(input_tensor, size)\n",
    "    \n",
    "    nan_values, idx = tf.unique(tf.gather(tf.where(tf.math.is_nan(sliced_tensor)), 0, axis=1))\n",
    "    nan_values = nan_values.numpy()\n",
    "  \n",
    "    msk = np.zeros((input_shape[0]), dtype=np.bool)\n",
    "    msk[nan_values] = True\n",
    "    msk = ~msk\n",
    "\n",
    "    sliced_tensor = tf.boolean_mask(sliced_tensor, msk , axis=0)\n",
    "    labels = tf.boolean_mask(labels , msk, axis=0)\n",
    "    \n",
    "    return sliced_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22c77f26-ecfd-4282-8733-7b926691c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.5001 - accuracy: 0.1400 - val_loss: 1.3915 - val_accuracy: 0.2400\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3526 - accuracy: 0.3400 - val_loss: 1.3861 - val_accuracy: 0.2700\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3918 - accuracy: 0.2400 - val_loss: 1.3805 - val_accuracy: 0.2500\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3967 - accuracy: 0.2600 - val_loss: 1.3782 - val_accuracy: 0.2800\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3621 - accuracy: 0.2800 - val_loss: 1.3776 - val_accuracy: 0.3200\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.3620 - accuracy: 0.2200 - val_loss: 1.3771 - val_accuracy: 0.3000\n",
      "Epoch 1\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.4178 - accuracy: 0.1800 - val_loss: 1.3779 - val_accuracy: 0.3200\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3597 - accuracy: 0.3000 - val_loss: 1.3780 - val_accuracy: 0.2600\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.3744 - accuracy: 0.3000 - val_loss: 1.3772 - val_accuracy: 0.2500\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.3474 - accuracy: 0.3200 - val_loss: 1.3757 - val_accuracy: 0.3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.3688 - accuracy: 0.3200 - val_loss: 1.3743 - val_accuracy: 0.3000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.3766 - accuracy: 0.2600 - val_loss: 1.3731 - val_accuracy: 0.3000\n",
      "Epoch 2\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.3644 - accuracy: 0.3600 - val_loss: 1.3606 - val_accuracy: 0.2900\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.3236 - accuracy: 0.3200 - val_loss: 1.3582 - val_accuracy: 0.3100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.3705 - accuracy: 0.2200 - val_loss: 1.3558 - val_accuracy: 0.3400\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.3445 - accuracy: 0.3200 - val_loss: 1.3534 - val_accuracy: 0.3600\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.3561 - accuracy: 0.3200 - val_loss: 1.3512 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.3234 - accuracy: 0.3265 - val_loss: 1.3496 - val_accuracy: 0.4600\n",
      "Epoch 3\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.3398 - accuracy: 0.2800 - val_loss: 1.3426 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2863 - accuracy: 0.3200 - val_loss: 1.3392 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.2863 - accuracy: 0.3600 - val_loss: 1.3351 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2401 - accuracy: 0.5000 - val_loss: 1.3311 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.3005 - accuracy: 0.3600 - val_loss: 1.3271 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3089 - accuracy: 0.3600 - val_loss: 1.3233 - val_accuracy: 0.4500\n",
      "Epoch 4\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2928 - accuracy: 0.3200 - val_loss: 1.3246 - val_accuracy: 0.3500\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2556 - accuracy: 0.4400 - val_loss: 1.3217 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2450 - accuracy: 0.4200 - val_loss: 1.3191 - val_accuracy: 0.3500\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.2602 - accuracy: 0.3600 - val_loss: 1.3188 - val_accuracy: 0.3100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2274 - accuracy: 0.4000 - val_loss: 1.3149 - val_accuracy: 0.2800\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 1.2981 - accuracy: 0.1800 - val_loss: 1.3080 - val_accuracy: 0.3600\n",
      "Epoch 5\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.2105 - accuracy: 0.4000 - val_loss: 1.3015 - val_accuracy: 0.3800\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.2905 - accuracy: 0.4000 - val_loss: 1.2984 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1992 - accuracy: 0.3800 - val_loss: 1.2942 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2713 - accuracy: 0.3878 - val_loss: 1.2940 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1837 - accuracy: 0.4600 - val_loss: 1.2937 - val_accuracy: 0.3700\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.2358 - accuracy: 0.3469 - val_loss: 1.2886 - val_accuracy: 0.3400\n",
      "Epoch 6\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1447 - accuracy: 0.3800 - val_loss: 1.2534 - val_accuracy: 0.3571\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.2072 - accuracy: 0.4400 - val_loss: 1.2434 - val_accuracy: 0.3980\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1515 - accuracy: 0.4898 - val_loss: 1.2349 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.2157 - accuracy: 0.4400 - val_loss: 1.2303 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2877 - accuracy: 0.3673 - val_loss: 1.2293 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2147 - accuracy: 0.4400 - val_loss: 1.2276 - val_accuracy: 0.4796\n",
      "Epoch 7\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.2042 - accuracy: 0.4000 - val_loss: 1.2330 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0848 - accuracy: 0.6000 - val_loss: 1.2341 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.0389 - accuracy: 0.5400 - val_loss: 1.2386 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.0852 - accuracy: 0.5200 - val_loss: 1.2436 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.2522 - accuracy: 0.4200 - val_loss: 1.2379 - val_accuracy: 0.4082\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2174 - accuracy: 0.3673 - val_loss: 1.2213 - val_accuracy: 0.4490\n",
      "Epoch 8\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3124 - accuracy: 0.4800 - val_loss: 1.2153 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0965 - accuracy: 0.4286 - val_loss: 1.2158 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3146 - accuracy: 0.3673 - val_loss: 1.2167 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2156 - accuracy: 0.4400 - val_loss: 1.2178 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1229 - accuracy: 0.5600 - val_loss: 1.2187 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1702 - accuracy: 0.4200 - val_loss: 1.2213 - val_accuracy: 0.5000\n",
      "Epoch 9\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1144 - accuracy: 0.5200 - val_loss: 1.2326 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1058 - accuracy: 0.4400 - val_loss: 1.2336 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0934 - accuracy: 0.5102 - val_loss: 1.2291 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2437 - accuracy: 0.4600 - val_loss: 1.2198 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3201 - accuracy: 0.3200 - val_loss: 1.2193 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.9917 - accuracy: 0.6000 - val_loss: 1.2187 - val_accuracy: 0.4100\n",
      "Epoch 10\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1272 - accuracy: 0.5000 - val_loss: 1.1900 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0364 - accuracy: 0.5306 - val_loss: 1.1843 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2397 - accuracy: 0.4000 - val_loss: 1.1794 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1770 - accuracy: 0.4600 - val_loss: 1.1789 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.2652 - accuracy: 0.3400 - val_loss: 1.1842 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0824 - accuracy: 0.5800 - val_loss: 1.1881 - val_accuracy: 0.5000\n",
      "Epoch 11\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2624 - accuracy: 0.3800 - val_loss: 1.2424 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1620 - accuracy: 0.5000 - val_loss: 1.2430 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.0066 - accuracy: 0.5600 - val_loss: 1.2450 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1403 - accuracy: 0.4200 - val_loss: 1.2449 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.0753 - accuracy: 0.5200 - val_loss: 1.2434 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 1.3473 - accuracy: 0.3600 - val_loss: 1.2336 - val_accuracy: 0.3900\n",
      "Epoch 12\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2058 - accuracy: 0.4400 - val_loss: 1.1849 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2243 - accuracy: 0.4600 - val_loss: 1.1877 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1016 - accuracy: 0.5102 - val_loss: 1.1867 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.1498 - accuracy: 0.4800 - val_loss: 1.1836 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1733 - accuracy: 0.5200 - val_loss: 1.1815 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0446 - accuracy: 0.5600 - val_loss: 1.1822 - val_accuracy: 0.4700\n",
      "Epoch 13\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.1879 - accuracy: 0.3800 - val_loss: 1.3325 - val_accuracy: 0.3800\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1464 - accuracy: 0.5600 - val_loss: 1.3282 - val_accuracy: 0.3700\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.1918 - accuracy: 0.4600 - val_loss: 1.3183 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2866 - accuracy: 0.4200 - val_loss: 1.3124 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.1184 - accuracy: 0.4600 - val_loss: 1.3127 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1277 - accuracy: 0.4600 - val_loss: 1.3184 - val_accuracy: 0.4100\n",
      "Epoch 14\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.0445 - accuracy: 0.5200 - val_loss: 1.1765 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.1330 - accuracy: 0.4200 - val_loss: 1.1731 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1353 - accuracy: 0.4800 - val_loss: 1.1696 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.0632 - accuracy: 0.5714 - val_loss: 1.1629 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.0107 - accuracy: 0.4800 - val_loss: 1.1565 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1818 - accuracy: 0.5400 - val_loss: 1.1553 - val_accuracy: 0.4490\n",
      "Epoch 15\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1527 - accuracy: 0.4800 - val_loss: 1.2090 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0879 - accuracy: 0.4600 - val_loss: 1.2060 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.9751 - accuracy: 0.5102 - val_loss: 1.2029 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0216 - accuracy: 0.5600 - val_loss: 1.2018 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1340 - accuracy: 0.4400 - val_loss: 1.2008 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4210 - accuracy: 0.4200 - val_loss: 1.2076 - val_accuracy: 0.4600\n",
      "Epoch 16\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1659 - accuracy: 0.4400 - val_loss: 1.1330 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.1266 - accuracy: 0.5200 - val_loss: 1.1412 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9984 - accuracy: 0.4600 - val_loss: 1.1373 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1248 - accuracy: 0.4800 - val_loss: 1.1423 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0895 - accuracy: 0.4800 - val_loss: 1.1420 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.4823 - accuracy: 0.3400 - val_loss: 1.1527 - val_accuracy: 0.5510\n",
      "Epoch 17\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.0290 - accuracy: 0.4600 - val_loss: 1.1720 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3199 - accuracy: 0.2800 - val_loss: 1.1774 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0158 - accuracy: 0.5400 - val_loss: 1.1809 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.1369 - accuracy: 0.4800 - val_loss: 1.1875 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0378 - accuracy: 0.6200 - val_loss: 1.1886 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1399 - accuracy: 0.4000 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
      "Epoch 18\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.1676 - accuracy: 0.4000 - val_loss: 1.1930 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1730 - accuracy: 0.4400 - val_loss: 1.1920 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0800 - accuracy: 0.4800 - val_loss: 1.1968 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0494 - accuracy: 0.5800 - val_loss: 1.2066 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1084 - accuracy: 0.4898 - val_loss: 1.2158 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.0740 - accuracy: 0.5800 - val_loss: 1.2216 - val_accuracy: 0.4082\n",
      "Epoch 19\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1372 - accuracy: 0.4200 - val_loss: 1.2826 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0762 - accuracy: 0.4200 - val_loss: 1.2861 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0166 - accuracy: 0.4600 - val_loss: 1.2861 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2691 - accuracy: 0.3200 - val_loss: 1.2829 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2526 - accuracy: 0.5000 - val_loss: 1.2808 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.1763 - accuracy: 0.4286 - val_loss: 1.2816 - val_accuracy: 0.4000\n",
      "Epoch 20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.0449 - accuracy: 0.4898 - val_loss: 1.2131 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1667 - accuracy: 0.4082 - val_loss: 1.2105 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1226 - accuracy: 0.4400 - val_loss: 1.2091 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9360 - accuracy: 0.5600 - val_loss: 1.2077 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0023 - accuracy: 0.5600 - val_loss: 1.2044 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0372 - accuracy: 0.4800 - val_loss: 1.2021 - val_accuracy: 0.4300\n",
      "Epoch 21\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1968 - accuracy: 0.4400 - val_loss: 1.1348 - val_accuracy: 0.4694\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.1350 - accuracy: 0.4898 - val_loss: 1.1397 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.0398 - accuracy: 0.6122 - val_loss: 1.1394 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1196 - accuracy: 0.5200 - val_loss: 1.1390 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1837 - accuracy: 0.5600 - val_loss: 1.1439 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1648 - accuracy: 0.3600 - val_loss: 1.1471 - val_accuracy: 0.4082\n",
      "Epoch 22\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1736 - accuracy: 0.4000 - val_loss: 1.1383 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1234 - accuracy: 0.4400 - val_loss: 1.1404 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9485 - accuracy: 0.6600 - val_loss: 1.1412 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0690 - accuracy: 0.4800 - val_loss: 1.1451 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0132 - accuracy: 0.6327 - val_loss: 1.1416 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0794 - accuracy: 0.5102 - val_loss: 1.1305 - val_accuracy: 0.5204\n",
      "Epoch 23\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9979 - accuracy: 0.5800 - val_loss: 1.1391 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9296 - accuracy: 0.5800 - val_loss: 1.1351 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9474 - accuracy: 0.5918 - val_loss: 1.1351 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.4100 - accuracy: 0.3400 - val_loss: 1.1433 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0867 - accuracy: 0.5200 - val_loss: 1.1488 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.2595 - accuracy: 0.4400 - val_loss: 1.1433 - val_accuracy: 0.4500\n",
      "Epoch 24\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2300 - accuracy: 0.4200 - val_loss: 1.1580 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1081 - accuracy: 0.5200 - val_loss: 1.1546 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.1031 - accuracy: 0.5400 - val_loss: 1.1549 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0032 - accuracy: 0.5000 - val_loss: 1.1516 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.2815 - accuracy: 0.4200 - val_loss: 1.1495 - val_accuracy: 0.4694\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1634 - accuracy: 0.5000 - val_loss: 1.1517 - val_accuracy: 0.4694\n",
      "Epoch 25\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.1307 - accuracy: 0.5102 - val_loss: 1.1567 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2656 - accuracy: 0.4800 - val_loss: 1.1626 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1844 - accuracy: 0.3600 - val_loss: 1.1690 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.8942 - accuracy: 0.7200 - val_loss: 1.1734 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0022 - accuracy: 0.5600 - val_loss: 1.1754 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1367 - accuracy: 0.5800 - val_loss: 1.1781 - val_accuracy: 0.4300\n",
      "Epoch 26\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.1435 - accuracy: 0.3800 - val_loss: 1.1736 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0708 - accuracy: 0.4600 - val_loss: 1.1722 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9593 - accuracy: 0.5600 - val_loss: 1.1650 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.2209 - accuracy: 0.4800 - val_loss: 1.1612 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.9477 - accuracy: 0.5600 - val_loss: 1.1529 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1546 - accuracy: 0.5102 - val_loss: 1.1443 - val_accuracy: 0.4286\n",
      "Epoch 27\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1351 - accuracy: 0.5306 - val_loss: 1.1349 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1759 - accuracy: 0.5400 - val_loss: 1.1343 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9804 - accuracy: 0.5400 - val_loss: 1.1332 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0209 - accuracy: 0.5600 - val_loss: 1.1298 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1356 - accuracy: 0.4600 - val_loss: 1.1280 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.9523 - accuracy: 0.5600 - val_loss: 1.1262 - val_accuracy: 0.4796\n",
      "Epoch 28\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0493 - accuracy: 0.4600 - val_loss: 1.2680 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1368 - accuracy: 0.4400 - val_loss: 1.2679 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1223 - accuracy: 0.4600 - val_loss: 1.2651 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.0306 - accuracy: 0.5400 - val_loss: 1.2576 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1166 - accuracy: 0.4600 - val_loss: 1.2538 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.0852 - accuracy: 0.5000 - val_loss: 1.2534 - val_accuracy: 0.4200\n",
      "Epoch 29\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0432 - accuracy: 0.5000 - val_loss: 1.1326 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1050 - accuracy: 0.4400 - val_loss: 1.1384 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.9460 - accuracy: 0.6400 - val_loss: 1.1390 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0118 - accuracy: 0.5714 - val_loss: 1.1401 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.4331 - accuracy: 0.3800 - val_loss: 1.1421 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1127 - accuracy: 0.5102 - val_loss: 1.1445 - val_accuracy: 0.5000\n",
      "Epoch 30\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1493 - accuracy: 0.4400 - val_loss: 1.1174 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9891 - accuracy: 0.6800 - val_loss: 1.1227 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9662 - accuracy: 0.5200 - val_loss: 1.1142 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0223 - accuracy: 0.5625 - val_loss: 1.0993 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9237 - accuracy: 0.6400 - val_loss: 1.0883 - val_accuracy: 0.5612\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1209 - accuracy: 0.4600 - val_loss: 1.0819 - val_accuracy: 0.5612\n",
      "Epoch 31\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9462 - accuracy: 0.6000 - val_loss: 1.1320 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2245 - accuracy: 0.3400 - val_loss: 1.1398 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0951 - accuracy: 0.5400 - val_loss: 1.1379 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0926 - accuracy: 0.5306 - val_loss: 1.1353 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0422 - accuracy: 0.4800 - val_loss: 1.1313 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1298 - accuracy: 0.3600 - val_loss: 1.1288 - val_accuracy: 0.5204\n",
      "Epoch 32\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0917 - accuracy: 0.4000 - val_loss: 1.1288 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.0864 - accuracy: 0.4800 - val_loss: 1.1495 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1357 - accuracy: 0.4600 - val_loss: 1.1659 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0269 - accuracy: 0.5600 - val_loss: 1.1786 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3438 - accuracy: 0.3600 - val_loss: 1.1764 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.2006 - accuracy: 0.4800 - val_loss: 1.1629 - val_accuracy: 0.5200\n",
      "Epoch 33\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9417 - accuracy: 0.7083 - val_loss: 1.1410 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1729 - accuracy: 0.4600 - val_loss: 1.1410 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0213 - accuracy: 0.5600 - val_loss: 1.1414 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0021 - accuracy: 0.5000 - val_loss: 1.1388 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0957 - accuracy: 0.5200 - val_loss: 1.1368 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0623 - accuracy: 0.5200 - val_loss: 1.1317 - val_accuracy: 0.4694\n",
      "Epoch 34\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9186 - accuracy: 0.6800 - val_loss: 1.1309 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0481 - accuracy: 0.5200 - val_loss: 1.1266 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.1526 - accuracy: 0.4200 - val_loss: 1.1259 - val_accuracy: 0.4286\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2396 - accuracy: 0.3750 - val_loss: 1.1267 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3571 - accuracy: 0.4400 - val_loss: 1.1302 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.0943 - accuracy: 0.5000 - val_loss: 1.1408 - val_accuracy: 0.4694\n",
      "Epoch 35\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.1865 - accuracy: 0.4000 - val_loss: 1.1663 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0014 - accuracy: 0.6200 - val_loss: 1.1637 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1181 - accuracy: 0.5400 - val_loss: 1.1569 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0137 - accuracy: 0.5000 - val_loss: 1.1554 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0304 - accuracy: 0.4600 - val_loss: 1.1594 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1285 - accuracy: 0.5000 - val_loss: 1.1613 - val_accuracy: 0.4545\n",
      "Epoch 36\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0462 - accuracy: 0.4400 - val_loss: 1.2293 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9921 - accuracy: 0.6400 - val_loss: 1.2259 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.2482 - accuracy: 0.3800 - val_loss: 1.2260 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0092 - accuracy: 0.5200 - val_loss: 1.2286 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0652 - accuracy: 0.5400 - val_loss: 1.2345 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9386 - accuracy: 0.6939 - val_loss: 1.2368 - val_accuracy: 0.4400\n",
      "Epoch 37\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.8506 - accuracy: 0.6667 - val_loss: 1.1959 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.0185 - accuracy: 0.5000 - val_loss: 1.1940 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.9862 - accuracy: 0.5800 - val_loss: 1.1810 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9375 - accuracy: 0.5800 - val_loss: 1.1695 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0792 - accuracy: 0.5600 - val_loss: 1.1616 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.0691 - accuracy: 0.5000 - val_loss: 1.1558 - val_accuracy: 0.4500\n",
      "Epoch 38\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0096 - accuracy: 0.5306 - val_loss: 1.0731 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1842 - accuracy: 0.5600 - val_loss: 1.0765 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0054 - accuracy: 0.5200 - val_loss: 1.0839 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.0210 - accuracy: 0.5400 - val_loss: 1.0882 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0834 - accuracy: 0.5000 - val_loss: 1.0924 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1344 - accuracy: 0.5000 - val_loss: 1.0979 - val_accuracy: 0.5204\n",
      "Epoch 39\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0957 - accuracy: 0.4400 - val_loss: 1.1476 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9481 - accuracy: 0.6200 - val_loss: 1.1520 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1368 - accuracy: 0.5000 - val_loss: 1.1569 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.1157 - accuracy: 0.4200 - val_loss: 1.1621 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.0485 - accuracy: 0.5200 - val_loss: 1.1613 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9157 - accuracy: 0.6000 - val_loss: 1.1571 - val_accuracy: 0.4848\n",
      "Epoch 40\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.8046 - accuracy: 0.6800 - val_loss: 1.1175 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.0980 - accuracy: 0.5000 - val_loss: 1.1094 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.9315 - accuracy: 0.5600 - val_loss: 1.1028 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1343 - accuracy: 0.4600 - val_loss: 1.0945 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.1395 - accuracy: 0.5000 - val_loss: 1.0930 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.2297 - accuracy: 0.4400 - val_loss: 1.1080 - val_accuracy: 0.4796\n",
      "Epoch 41\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1762 - accuracy: 0.4400 - val_loss: 1.1367 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1287 - accuracy: 0.5400 - val_loss: 1.1619 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2782 - accuracy: 0.4200 - val_loss: 1.1631 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0483 - accuracy: 0.5600 - val_loss: 1.1504 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9777 - accuracy: 0.5600 - val_loss: 1.1441 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9089 - accuracy: 0.6327 - val_loss: 1.1409 - val_accuracy: 0.5100\n",
      "Epoch 42\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9926 - accuracy: 0.5000 - val_loss: 1.1026 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0037 - accuracy: 0.4800 - val_loss: 1.1048 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.0458 - accuracy: 0.5000 - val_loss: 1.1047 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 1.0032 - accuracy: 0.5400 - val_loss: 1.0977 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0495 - accuracy: 0.5000 - val_loss: 1.0852 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0249 - accuracy: 0.5400 - val_loss: 1.0790 - val_accuracy: 0.5400\n",
      "Epoch 43\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.9158 - accuracy: 0.6600 - val_loss: 1.1307 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.0791 - accuracy: 0.5800 - val_loss: 1.1380 - val_accuracy: 0.4444\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0164 - accuracy: 0.5102 - val_loss: 1.1416 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0212 - accuracy: 0.5200 - val_loss: 1.1371 - val_accuracy: 0.4444\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0885 - accuracy: 0.5800 - val_loss: 1.1339 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1281 - accuracy: 0.4400 - val_loss: 1.1284 - val_accuracy: 0.4747\n",
      "Epoch 44\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0002 - accuracy: 0.4800 - val_loss: 1.0261 - val_accuracy: 0.6224\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.9055 - accuracy: 0.6122 - val_loss: 1.0269 - val_accuracy: 0.6020\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9420 - accuracy: 0.6000 - val_loss: 1.0237 - val_accuracy: 0.6020\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.9176 - accuracy: 0.5306 - val_loss: 1.0176 - val_accuracy: 0.6122\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1700 - accuracy: 0.4200 - val_loss: 1.0188 - val_accuracy: 0.6020\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.9352 - accuracy: 0.5600 - val_loss: 1.0203 - val_accuracy: 0.5816\n",
      "Epoch 45\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.9892 - accuracy: 0.5800 - val_loss: 1.1008 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0443 - accuracy: 0.4800 - val_loss: 1.0997 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.9513 - accuracy: 0.5600 - val_loss: 1.1011 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0676 - accuracy: 0.4800 - val_loss: 1.1050 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.0891 - accuracy: 0.4800 - val_loss: 1.1113 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9769 - accuracy: 0.6000 - val_loss: 1.1148 - val_accuracy: 0.4600\n",
      "Epoch 46\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2145 - accuracy: 0.4600 - val_loss: 1.0975 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.9012 - accuracy: 0.5200 - val_loss: 1.1273 - val_accuracy: 0.4694\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.0531 - accuracy: 0.5510 - val_loss: 1.1241 - val_accuracy: 0.4694\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.0630 - accuracy: 0.5800 - val_loss: 1.1093 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.2576 - accuracy: 0.5400 - val_loss: 1.0959 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.0142 - accuracy: 0.5600 - val_loss: 1.0990 - val_accuracy: 0.4796\n",
      "Epoch 47\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.1632 - accuracy: 0.5000 - val_loss: 1.1065 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.0473 - accuracy: 0.5306 - val_loss: 1.1042 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9037 - accuracy: 0.6200 - val_loss: 1.1016 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.0560 - accuracy: 0.5800 - val_loss: 1.0961 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.0232 - accuracy: 0.6000 - val_loss: 1.0855 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0342 - accuracy: 0.5000 - val_loss: 1.0806 - val_accuracy: 0.5200\n",
      "Epoch 48\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.0675 - accuracy: 0.5200 - val_loss: 1.1130 - val_accuracy: 0.4343\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.1498 - accuracy: 0.4200 - val_loss: 1.1190 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0204 - accuracy: 0.4694 - val_loss: 1.1245 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.0187 - accuracy: 0.4600 - val_loss: 1.1274 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2136 - accuracy: 0.4800 - val_loss: 1.1299 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.9321 - accuracy: 0.5400 - val_loss: 1.1302 - val_accuracy: 0.4949\n",
      "Epoch 49\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.1526 - accuracy: 0.4200 - val_loss: 1.1061 - val_accuracy: 0.4694\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0025 - accuracy: 0.5400 - val_loss: 1.1140 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.1897 - accuracy: 0.4898 - val_loss: 1.1026 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1260 - accuracy: 0.4400 - val_loss: 1.0888 - val_accuracy: 0.5714\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.8385 - accuracy: 0.6800 - val_loss: 1.0865 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.9492 - accuracy: 0.5800 - val_loss: 1.0894 - val_accuracy: 0.5612\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_ds = train_dataset.shuffle(n_train).batch(batch_size)\n",
    "    val_ds = validation_dataset.shuffle(n_test).batch(n_test)\n",
    "    \n",
    "    x_val, y_val, length_val = next(iter(val_ds))\n",
    "    x_val, y_val = slice_accordingly(x_val, y_val)\n",
    "    \n",
    "    for features, labels, lengths in train_ds:\n",
    "        features, labels = slice_accordingly(features, labels)\n",
    "        \n",
    "        history = model.fit(features, labels,\n",
    "                           validation_data=(x_val, y_val),verbose=1)\n",
    "        predictions = model.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
