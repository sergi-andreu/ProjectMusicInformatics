{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0398eec-5842-4ca8-b6ac-1c608701c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee4c7a5-bec0-46c4-ba87-c6a146c994b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = np.load(\"../preprocessing/MFCCs/MFCC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984cc5a9-043d-4989-b52c-0a7bc31bd3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = (MFCCs - np.nanmean(MFCCs))/np.nanstd(MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "571f061a-4c46-400d-a3d1-e81f8bca7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.49531220e+00 -7.49531220e+00 -7.49531220e+00 ... -2.28470204e+00\n",
      "  -2.28154364e+00 -2.46218506e+00]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  2.66772499e+00\n",
      "   2.75375372e+00  2.64647346e+00]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ... -3.14520361e-01\n",
      "  -2.91229857e-01 -4.12438540e-01]\n",
      " ...\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  3.09898681e-02\n",
      "   4.16713754e-03 -1.56268668e-03]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  5.42445234e-02\n",
      "   1.41780647e-01  9.51679247e-02]\n",
      " [ 3.78452600e-03  3.78452600e-03  3.78452600e-03 ...  4.73457277e-02\n",
      "   6.71201664e-02  1.52584397e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(MFCCs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe39aa7-119e-4906-8fa8-eaae2615caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_songs = pd.read_csv(\"../Info/info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d86c1c-3986-4d19-91d8-6a0509686f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_songs = pd.read_csv(\"../preprocessing/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5920ce90-7409-4223-b87f-312d38dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_label = \"genre\"\n",
    "\n",
    "if select_label == \"genre\":\n",
    "    labels = label_songs[select_label].map({\"classical\":0, \"electronic\":1, \"pop\":2, \"rock\":3})\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df75dcd-3c43-453d-982e-81914596b266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Song length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Track ID  Song length\n",
       "0           1          600\n",
       "1          10          600\n",
       "2         100          600\n",
       "3          11          600\n",
       "4          12          600\n",
       "..        ...          ...\n",
       "395       395          600\n",
       "396       396          600\n",
       "397       397          600\n",
       "398       398          600\n",
       "399       399          600\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_songs = pd.DataFrame(info_songs[\"Track ID\"])\n",
    "length_songs[\"Song length\"] = info_songs[\"Duration\"]*10\n",
    "length_songs[\"Song length\"] = length_songs[\"Song length\"].astype(int)\n",
    "length_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53af9ef3-1908-49b4-9ab8-2e057cdb8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(length_songs)\n",
    "idx = np.random.permutation(n_data)\n",
    "length_songs = length_songs.reindex(idx)[\"Song length\"].to_numpy()\n",
    "MFCCs = MFCCs[idx, :, :]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b5f3129-a9ba-4944-85a0-25085b6df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a47f5e-962e-4040-b8d7-488523b37cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_validation = 0.25\n",
    "n_test = int(fraction_validation*len(labels))\n",
    "n_train = len(labels) - n_test\n",
    "\n",
    "train_features, train_labels, train_length = MFCCs[:n_train], labels[:n_train], length_songs[:n_train]\n",
    "validation_features, validation_labels, validation_length = MFCCs[n_train:], labels[n_train:], length_songs[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b2156b-ce32-483b-afa3-96554f470f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels, train_length))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels, validation_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a856cae8-bd13-4456-80c0-47940da6a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#sample_size = (20, 50, 1)\n",
    "sample_size = (20, 100, 1)\n",
    "\n",
    "drop_out_rate = 0.2\n",
    "\n",
    "# very simple keras Sequential model\n",
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (1, 10), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.Conv2D(32, (1, 5), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(50, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93708a8d-dff3-4e19-84ba-0bd895d344af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 100, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 91, 16)        176       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 87, 32)        2592      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 87, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13760)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                688050    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 691,022\n",
      "Trainable params: 691,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ee0abf-f165-4cb6-9bab-d6cfbaf91d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 20, 100, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 76, 16)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 62, 32)        7712      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 48, 32)        15392     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 9, 23, 32)         4128      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6624)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6624)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                212000    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 239,780\n",
      "Trainable params: 239,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (1, 25), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.Conv2D(32, (1, 15), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Conv2D(32, (1, 15), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Conv2D(32, (2,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(2*drop_out_rate)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(input_tensor, output_tensor)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54a5944b-7563-4fd0-abcd-1dfed65f94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 20, 100, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 98, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 49, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 47, 32)         4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 23, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 22, 32)         2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 11, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 10, 16)         2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2592      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 11,668\n",
      "Trainable params: 11,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (1,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(1,2))(x)\n",
    "\n",
    "x = layers.Conv2D(16, (2,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(2*drop_out_rate)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(input_tensor, output_tensor)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66f45a25-2f54-413f-b3b0-832f9285ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_1\n",
    "model = model_2\n",
    "#model = model_3\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1a29b84-c1aa-43ba-8a8d-99db7d769475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_accordingly(input_tensor, labels, size=sample_size):\n",
    "\n",
    "    input_shape = (tf.shape(input_tensor).numpy())\n",
    "    \n",
    "    input_shape[1], input_shape[2] = size[0], size[1]\n",
    "    size = input_shape\n",
    "    \n",
    "    sliced_tensor = tf.image.random_crop(input_tensor, size)\n",
    "    \n",
    "    nan_values, idx = tf.unique(tf.gather(tf.where(tf.math.is_nan(sliced_tensor)), 0, axis=1))\n",
    "    nan_values = nan_values.numpy()\n",
    "  \n",
    "    msk = np.zeros((input_shape[0]), dtype=np.bool)\n",
    "    msk[nan_values] = True\n",
    "    msk = ~msk\n",
    "\n",
    "    sliced_tensor = tf.boolean_mask(sliced_tensor, msk , axis=0)\n",
    "    labels = tf.boolean_mask(labels , msk, axis=0)\n",
    "    \n",
    "    return sliced_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22c77f26-ecfd-4282-8733-7b926691c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 1.3814 - accuracy: 0.2600 - val_loss: 1.3805 - val_accuracy: 0.2653\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.4147 - accuracy: 0.1400 - val_loss: 1.3655 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 1.3907 - accuracy: 0.3000 - val_loss: 1.3568 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 1.3302 - accuracy: 0.4000 - val_loss: 1.3524 - val_accuracy: 0.2347\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 1.3714 - accuracy: 0.3600 - val_loss: 1.3437 - val_accuracy: 0.2857\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.4231 - accuracy: 0.1600 - val_loss: 1.3860 - val_accuracy: 0.2143\n",
      "Epoch 1\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 1.3735 - accuracy: 0.3061 - val_loss: 1.3380 - val_accuracy: 0.2900\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.2882 - accuracy: 0.4400 - val_loss: 1.3114 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.2963 - accuracy: 0.4400 - val_loss: 1.3030 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 1.3243 - accuracy: 0.3400 - val_loss: 1.2928 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.3018 - accuracy: 0.3200 - val_loss: 1.2820 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.2679 - accuracy: 0.4400 - val_loss: 1.2631 - val_accuracy: 0.4300\n",
      "Epoch 2\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 1.2406 - accuracy: 0.4000 - val_loss: 1.2380 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 1.3912 - accuracy: 0.4600 - val_loss: 1.2711 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 1.1631 - accuracy: 0.4800 - val_loss: 1.2798 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.1625 - accuracy: 0.3800 - val_loss: 1.2404 - val_accuracy: 0.3980\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 1.1911 - accuracy: 0.3600 - val_loss: 1.2038 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.0613 - accuracy: 0.4898 - val_loss: 1.1719 - val_accuracy: 0.4694\n",
      "Epoch 3\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.2369 - accuracy: 0.4200 - val_loss: 1.1556 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 1.0613 - accuracy: 0.5714 - val_loss: 1.1594 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 1.1088 - accuracy: 0.5600 - val_loss: 1.1533 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.1130 - accuracy: 0.5000 - val_loss: 1.1507 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0956 - accuracy: 0.5714 - val_loss: 1.1608 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.1524 - accuracy: 0.5200 - val_loss: 1.1904 - val_accuracy: 0.4444\n",
      "Epoch 4\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 1.1262 - accuracy: 0.3800 - val_loss: 1.2165 - val_accuracy: 0.4444\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 1.2148 - accuracy: 0.5000 - val_loss: 1.1559 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 1.1507 - accuracy: 0.5200 - val_loss: 1.2028 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 1.1742 - accuracy: 0.5000 - val_loss: 1.2253 - val_accuracy: 0.4444\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 1.1548 - accuracy: 0.4600 - val_loss: 1.2009 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 1.1851 - accuracy: 0.4200 - val_loss: 1.2025 - val_accuracy: 0.4242\n",
      "Epoch 5\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 1.1416 - accuracy: 0.5200 - val_loss: 1.2251 - val_accuracy: 0.4343\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 1.1269 - accuracy: 0.5200 - val_loss: 1.1923 - val_accuracy: 0.4141\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.1638 - accuracy: 0.5000 - val_loss: 1.1399 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.0910 - accuracy: 0.6000 - val_loss: 1.1676 - val_accuracy: 0.4141\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 1.1334 - accuracy: 0.5306 - val_loss: 1.1274 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 1.0724 - accuracy: 0.4600 - val_loss: 1.1400 - val_accuracy: 0.5253\n",
      "Epoch 6\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 1.2513 - accuracy: 0.5000 - val_loss: 1.1250 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.9664 - accuracy: 0.5600 - val_loss: 1.1159 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.1137 - accuracy: 0.5306 - val_loss: 1.1036 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.0518 - accuracy: 0.5600 - val_loss: 1.0977 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 1.1143 - accuracy: 0.4082 - val_loss: 1.0739 - val_accuracy: 0.5455\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.9270 - accuracy: 0.6600 - val_loss: 1.0746 - val_accuracy: 0.4949\n",
      "Epoch 7\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.2487 - accuracy: 0.4800 - val_loss: 1.0192 - val_accuracy: 0.5900\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.9584 - accuracy: 0.6200 - val_loss: 1.0264 - val_accuracy: 0.5700\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.0344 - accuracy: 0.5714 - val_loss: 1.0235 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 1.1013 - accuracy: 0.4800 - val_loss: 1.0213 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.9851 - accuracy: 0.6200 - val_loss: 1.0105 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.8718 - accuracy: 0.6400 - val_loss: 0.9971 - val_accuracy: 0.5100\n",
      "Epoch 8\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.8418 - accuracy: 0.6000 - val_loss: 1.3149 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 1.2031 - accuracy: 0.4600 - val_loss: 1.3370 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.0048 - accuracy: 0.5510 - val_loss: 1.3572 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.8390 - accuracy: 0.5600 - val_loss: 1.3854 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.9530 - accuracy: 0.6400 - val_loss: 1.3591 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.9868 - accuracy: 0.6200 - val_loss: 1.3358 - val_accuracy: 0.4000\n",
      "Epoch 9\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.9431 - accuracy: 0.6200 - val_loss: 1.0807 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.7920 - accuracy: 0.7200 - val_loss: 1.1204 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.9714 - accuracy: 0.5200 - val_loss: 1.1741 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.2024 - accuracy: 0.3800 - val_loss: 1.0794 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.3691 - accuracy: 0.4600 - val_loss: 1.1414 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 1.1441 - accuracy: 0.4400 - val_loss: 1.1263 - val_accuracy: 0.4700\n",
      "Epoch 10\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 1.2357 - accuracy: 0.4400 - val_loss: 1.1420 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 1.0173 - accuracy: 0.5918 - val_loss: 1.1726 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 1.2308 - accuracy: 0.4400 - val_loss: 1.1827 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 1.0854 - accuracy: 0.5600 - val_loss: 1.1782 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.1681 - accuracy: 0.5600 - val_loss: 1.1788 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 1.1055 - accuracy: 0.5000 - val_loss: 1.1843 - val_accuracy: 0.4900\n",
      "Epoch 11\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.0162 - accuracy: 0.6400 - val_loss: 1.1311 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.9780 - accuracy: 0.6400 - val_loss: 1.1199 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 1.2948 - accuracy: 0.4200 - val_loss: 1.1350 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.0126 - accuracy: 0.4694 - val_loss: 1.1318 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 1.0445 - accuracy: 0.5400 - val_loss: 1.0869 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.1010 - accuracy: 0.5000 - val_loss: 1.0851 - val_accuracy: 0.5204\n",
      "Epoch 12\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.0971 - accuracy: 0.5200 - val_loss: 1.1076 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 0.8725 - accuracy: 0.7000 - val_loss: 1.1061 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.9581 - accuracy: 0.5800 - val_loss: 1.1033 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.1030 - accuracy: 0.5600 - val_loss: 1.1005 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 1.1465 - accuracy: 0.5000 - val_loss: 1.0900 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 1.0546 - accuracy: 0.5400 - val_loss: 1.0792 - val_accuracy: 0.4848\n",
      "Epoch 13\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.8902 - accuracy: 0.6122 - val_loss: 1.0876 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.0471 - accuracy: 0.5400 - val_loss: 1.0835 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.9013 - accuracy: 0.5306 - val_loss: 1.0843 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.9812 - accuracy: 0.5800 - val_loss: 1.0971 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.9934 - accuracy: 0.5200 - val_loss: 1.0994 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.1857 - accuracy: 0.5918 - val_loss: 1.0736 - val_accuracy: 0.5253\n",
      "Epoch 14\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 1.1970 - accuracy: 0.5000 - val_loss: 1.0438 - val_accuracy: 0.5612\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.0681 - accuracy: 0.4800 - val_loss: 1.0430 - val_accuracy: 0.5714\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.8366 - accuracy: 0.6400 - val_loss: 1.0547 - val_accuracy: 0.5816\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.0263 - accuracy: 0.5306 - val_loss: 1.0797 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.2685 - accuracy: 0.4800 - val_loss: 1.0774 - val_accuracy: 0.5612\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.9837 - accuracy: 0.5200 - val_loss: 1.0498 - val_accuracy: 0.5510\n",
      "Epoch 15\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.9419 - accuracy: 0.7000 - val_loss: 1.0620 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 1.1161 - accuracy: 0.6200 - val_loss: 1.0753 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.9958 - accuracy: 0.4800 - val_loss: 1.0981 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.1669 - accuracy: 0.4600 - val_loss: 1.1004 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 1.0072 - accuracy: 0.5200 - val_loss: 1.0930 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.1658 - accuracy: 0.4600 - val_loss: 1.1009 - val_accuracy: 0.4949\n",
      "Epoch 16\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 1.1513 - accuracy: 0.4400 - val_loss: 1.1019 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.0041 - accuracy: 0.5800 - val_loss: 1.1171 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.0008 - accuracy: 0.5400 - val_loss: 1.1259 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.9093 - accuracy: 0.5918 - val_loss: 1.1234 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 1.1561 - accuracy: 0.5200 - val_loss: 1.1119 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.9362 - accuracy: 0.6531 - val_loss: 1.1178 - val_accuracy: 0.5000\n",
      "Epoch 17\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.9137 - accuracy: 0.6200 - val_loss: 1.0681 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.8683 - accuracy: 0.6000 - val_loss: 1.0571 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.0144 - accuracy: 0.5800 - val_loss: 1.0427 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.9466 - accuracy: 0.5200 - val_loss: 1.0529 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.9658 - accuracy: 0.6400 - val_loss: 1.0535 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 1.3453 - accuracy: 0.5400 - val_loss: 1.0313 - val_accuracy: 0.5510\n",
      "Epoch 18\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.9283 - accuracy: 0.5510 - val_loss: 1.1220 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.9730 - accuracy: 0.5400 - val_loss: 1.1376 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.0354 - accuracy: 0.5800 - val_loss: 1.1325 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.9120 - accuracy: 0.6000 - val_loss: 1.1248 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 1.1359 - accuracy: 0.5000 - val_loss: 1.0975 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.9063 - accuracy: 0.5400 - val_loss: 1.0749 - val_accuracy: 0.5152\n",
      "Epoch 19\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.0758 - accuracy: 0.5000 - val_loss: 1.0239 - val_accuracy: 0.5800\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.8787 - accuracy: 0.6000 - val_loss: 1.0242 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.6741 - accuracy: 0.7959 - val_loss: 1.0242 - val_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.8641 - accuracy: 0.5800 - val_loss: 1.0380 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 0.9342 - accuracy: 0.6531 - val_loss: 1.0404 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.9216 - accuracy: 0.5200 - val_loss: 1.0328 - val_accuracy: 0.5600\n",
      "Epoch 20\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 1.0065 - accuracy: 0.6200 - val_loss: 1.2426 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 368ms/step - loss: 1.1892 - accuracy: 0.3600 - val_loss: 1.1889 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.7895 - accuracy: 0.6200 - val_loss: 1.1518 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.8665 - accuracy: 0.6122 - val_loss: 1.1101 - val_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.8409 - accuracy: 0.6400 - val_loss: 1.1012 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 1.1415 - accuracy: 0.5600 - val_loss: 1.1071 - val_accuracy: 0.5400\n",
      "Epoch 21\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 1.0545 - accuracy: 0.5400 - val_loss: 0.9338 - val_accuracy: 0.5700\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.8599 - accuracy: 0.6800 - val_loss: 0.9501 - val_accuracy: 0.5900\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 1.0765 - accuracy: 0.4800 - val_loss: 0.9914 - val_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.9535 - accuracy: 0.6600 - val_loss: 0.9811 - val_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.8777 - accuracy: 0.6400 - val_loss: 0.9580 - val_accuracy: 0.5900\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.7099 - accuracy: 0.7400 - val_loss: 0.9707 - val_accuracy: 0.5900\n",
      "Epoch 22\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.8564 - accuracy: 0.6800 - val_loss: 1.1316 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 1.1970 - accuracy: 0.4400 - val_loss: 1.1873 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 0.9309 - accuracy: 0.5600 - val_loss: 1.1036 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.7707 - accuracy: 0.7400 - val_loss: 1.0583 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.9136 - accuracy: 0.6000 - val_loss: 1.0555 - val_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.8891 - accuracy: 0.6667 - val_loss: 1.0501 - val_accuracy: 0.5500\n",
      "Epoch 23\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.9624 - accuracy: 0.5800 - val_loss: 0.9721 - val_accuracy: 0.6100\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.8031 - accuracy: 0.6200 - val_loss: 1.0009 - val_accuracy: 0.5800\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 1.0508 - accuracy: 0.6200 - val_loss: 0.9853 - val_accuracy: 0.6200\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.8938 - accuracy: 0.6327 - val_loss: 0.9932 - val_accuracy: 0.5700\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 1.0304 - accuracy: 0.5600 - val_loss: 1.0063 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.5868 - accuracy: 0.5000 - val_loss: 1.0404 - val_accuracy: 0.5000\n",
      "Epoch 24\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.9155 - accuracy: 0.6200 - val_loss: 1.1212 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 1.0048 - accuracy: 0.4800 - val_loss: 1.1088 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.9562 - accuracy: 0.6200 - val_loss: 1.0930 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 1.1433 - accuracy: 0.3400 - val_loss: 1.0947 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.8344 - accuracy: 0.6600 - val_loss: 1.0947 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 1.0616 - accuracy: 0.5800 - val_loss: 1.0910 - val_accuracy: 0.5354\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_ds = train_dataset.shuffle(n_train).batch(batch_size)\n",
    "    val_ds = validation_dataset.shuffle(n_test).batch(n_test)\n",
    "    \n",
    "    x_val, y_val, length_val = next(iter(val_ds))\n",
    "    x_val, y_val = slice_accordingly(x_val, y_val)\n",
    "    \n",
    "    for features, labels, lengths in train_ds:\n",
    "        features, labels = slice_accordingly(features, labels)\n",
    "        \n",
    "        history = model.fit(features, labels,\n",
    "                           validation_data=(x_val, y_val),verbose=1)\n",
    "        predictions = model.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
