{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0398eec-5842-4ca8-b6ac-1c608701c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee4c7a5-bec0-46c4-ba87-c6a146c994b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = np.load(\"../preprocessing/MFCCs/MFCC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984cc5a9-043d-4989-b52c-0a7bc31bd3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 20, 6000)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(MFCCs))\n",
    "\n",
    "MFCCs = (MFCCs - np.mean(MFCCs))/np.std(MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe39aa7-119e-4906-8fa8-eaae2615caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_songs = pd.read_csv(\"../Info/info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d86c1c-3986-4d19-91d8-6a0509686f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_songs = pd.read_csv(\"../preprocessing/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5920ce90-7409-4223-b87f-312d38dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_label = \"genre\"\n",
    "\n",
    "if select_label == \"genre\":\n",
    "    labels = label_songs[select_label].map({\"classical\":0, \"electronic\":1, \"pop\":2, \"rock\":3})\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df75dcd-3c43-453d-982e-81914596b266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Song length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Track ID  Song length\n",
       "0           1          600\n",
       "1          10          600\n",
       "2         100          600\n",
       "3          11          600\n",
       "4          12          600\n",
       "..        ...          ...\n",
       "395       395          600\n",
       "396       396          600\n",
       "397       397          600\n",
       "398       398          600\n",
       "399       399          600\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_songs = pd.DataFrame(info_songs[\"Track ID\"])\n",
    "length_songs[\"Song length\"] = info_songs[\"Duration\"]*10\n",
    "length_songs[\"Song length\"] = length_songs[\"Song length\"].astype(int)\n",
    "length_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53af9ef3-1908-49b4-9ab8-2e057cdb8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(length_songs)\n",
    "idx = np.random.permutation(n_data)\n",
    "length_songs = length_songs.reindex(idx)[\"Song length\"].to_numpy()\n",
    "MFCCs = MFCCs[idx, :, :]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5f3129-a9ba-4944-85a0-25085b6df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a47f5e-962e-4040-b8d7-488523b37cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_validation = 0.25\n",
    "n_test = int(fraction_validation*len(labels))\n",
    "n_train = len(labels) - n_test\n",
    "\n",
    "train_features, train_labels, train_length = MFCCs[:n_train], labels[:n_train], length_songs[:n_train]\n",
    "validation_features, validation_labels, validation_length = MFCCs[n_train:], labels[n_train:], length_songs[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b2156b-ce32-483b-afa3-96554f470f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels, train_length))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels, validation_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a856cae8-bd13-4456-80c0-47940da6a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "sample_size = (20, 50, 1)\n",
    "\n",
    "drop_out_rate = 0.2\n",
    "\n",
    "# very simple keras Sequential model\n",
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (1, 10), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.Conv2D(32, (1, 5), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93708a8d-dff3-4e19-84ba-0bd895d344af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 20, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 20, 41, 16)        176       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 20, 37, 32)        2592      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 20, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 10, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5760)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               1474816   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 1,478,612\n",
      "Trainable params: 1,478,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5ee0abf-f165-4cb6-9bab-d6cfbaf91d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 20, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 20, 41, 16)        176       \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 20, 27, 32)        7712      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 20, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 10, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 9, 12, 32)         4128      \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                110624    \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 122,772\n",
      "Trainable params: 122,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (1, 10), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.Conv2D(32, (1, 15), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Conv2D(32, (2,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(2*drop_out_rate)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(input_tensor, output_tensor)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54a5944b-7563-4fd0-abcd-1dfed65f94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, 20, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 18, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 9, 24, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 7, 22, 32)         4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 3, 11, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 3, 10, 32)         2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 3, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 2, 4, 16)          2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 1, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 10,132\n",
      "Trainable params: 10,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(16, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (1,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(1,2))(x)\n",
    "\n",
    "x = layers.Conv2D(16, (2,2), padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(2*drop_out_rate)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(input_tensor, output_tensor)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66f45a25-2f54-413f-b3b0-832f9285ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_1\n",
    "model = model_2\n",
    "model = model_3\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1a29b84-c1aa-43ba-8a8d-99db7d769475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_accordingly(input_tensor, labels, size=sample_size):\n",
    "\n",
    "    input_shape = (tf.shape(input_tensor).numpy())\n",
    "    \n",
    "    input_shape[1], input_shape[2] = size[0], size[1]\n",
    "    size = input_shape\n",
    "    \n",
    "    sliced_tensor = tf.image.random_crop(input_tensor, size)\n",
    "    \n",
    "    nan_values, idx = tf.unique(tf.gather(tf.where(tf.math.is_nan(sliced_tensor)), 0, axis=1))\n",
    "    nan_values = nan_values.numpy()\n",
    "  \n",
    "    msk = np.zeros((input_shape[0]), dtype=np.bool)\n",
    "    msk[nan_values] = True\n",
    "    msk = ~msk\n",
    "\n",
    "    sliced_tensor = tf.boolean_mask(sliced_tensor, msk , axis=0)\n",
    "    labels = tf.boolean_mask(labels , msk, axis=0)\n",
    "    \n",
    "    return sliced_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22c77f26-ecfd-4282-8733-7b926691c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "2/2 [==============================] - 1s 253ms/step - loss: 13.7492 - accuracy: 0.3200 - val_loss: 6.1710 - val_accuracy: 0.2222\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.2333 - accuracy: 0.2600 - val_loss: 3.3347 - val_accuracy: 0.2121\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.4213 - accuracy: 0.3000 - val_loss: 2.2134 - val_accuracy: 0.2020\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.9316 - accuracy: 0.2000 - val_loss: 1.7191 - val_accuracy: 0.2626\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.0447 - accuracy: 0.2400 - val_loss: 1.5677 - val_accuracy: 0.3232\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.9950 - accuracy: 0.3000 - val_loss: 1.5014 - val_accuracy: 0.3030\n",
      "Epoch 1\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.8465 - accuracy: 0.2600 - val_loss: 1.4975 - val_accuracy: 0.2600\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.9314 - accuracy: 0.1600 - val_loss: 1.4533 - val_accuracy: 0.2500\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.6462 - accuracy: 0.2600 - val_loss: 1.4344 - val_accuracy: 0.2700\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.6296 - accuracy: 0.2600 - val_loss: 1.3997 - val_accuracy: 0.2900\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.5238 - accuracy: 0.3400 - val_loss: 1.4006 - val_accuracy: 0.2800\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.5301 - accuracy: 0.2800 - val_loss: 1.4179 - val_accuracy: 0.2300\n",
      "Epoch 2\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.6486 - accuracy: 0.3200 - val_loss: 1.3667 - val_accuracy: 0.2800\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.4831 - accuracy: 0.2200 - val_loss: 1.3648 - val_accuracy: 0.2700\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.4205 - accuracy: 0.2200 - val_loss: 1.3747 - val_accuracy: 0.2200\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.4213 - accuracy: 0.2245 - val_loss: 1.3780 - val_accuracy: 0.2900\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.4011 - accuracy: 0.2600 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3800 - accuracy: 0.3000 - val_loss: 1.3837 - val_accuracy: 0.2600\n",
      "Epoch 3\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.3875 - accuracy: 0.2800 - val_loss: 1.3782 - val_accuracy: 0.2887\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.4291 - accuracy: 0.1400 - val_loss: 1.3730 - val_accuracy: 0.3299\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.3832 - accuracy: 0.3400 - val_loss: 1.3693 - val_accuracy: 0.3402\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3615 - accuracy: 0.3400 - val_loss: 1.3683 - val_accuracy: 0.3711\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.3395 - accuracy: 0.2800 - val_loss: 1.3658 - val_accuracy: 0.4124\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.3368 - accuracy: 0.3600 - val_loss: 1.3593 - val_accuracy: 0.3814\n",
      "Epoch 4\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.3992 - accuracy: 0.3200 - val_loss: 1.3521 - val_accuracy: 0.3571\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3366 - accuracy: 0.4000 - val_loss: 1.3468 - val_accuracy: 0.3163\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3885 - accuracy: 0.2800 - val_loss: 1.3451 - val_accuracy: 0.3469\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3327 - accuracy: 0.4000 - val_loss: 1.3446 - val_accuracy: 0.3265\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3666 - accuracy: 0.2400 - val_loss: 1.3432 - val_accuracy: 0.3571\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3737 - accuracy: 0.3200 - val_loss: 1.3416 - val_accuracy: 0.3469\n",
      "Epoch 5\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.3544 - accuracy: 0.3400 - val_loss: 1.3518 - val_accuracy: 0.3505\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3339 - accuracy: 0.3600 - val_loss: 1.3488 - val_accuracy: 0.3402\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3541 - accuracy: 0.4200 - val_loss: 1.3440 - val_accuracy: 0.3402\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.3663 - accuracy: 0.3000 - val_loss: 1.3388 - val_accuracy: 0.3505\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3791 - accuracy: 0.3000 - val_loss: 1.3363 - val_accuracy: 0.3505\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2992 - accuracy: 0.3600 - val_loss: 1.3353 - val_accuracy: 0.3608\n",
      "Epoch 6\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 1.3424 - accuracy: 0.3400 - val_loss: 1.3432 - val_accuracy: 0.3776\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3542 - accuracy: 0.3200 - val_loss: 1.3417 - val_accuracy: 0.3776\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3073 - accuracy: 0.3600 - val_loss: 1.3408 - val_accuracy: 0.3673\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2847 - accuracy: 0.4694 - val_loss: 1.3400 - val_accuracy: 0.3673\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3460 - accuracy: 0.3200 - val_loss: 1.3390 - val_accuracy: 0.3673\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.3705 - accuracy: 0.2600 - val_loss: 1.3381 - val_accuracy: 0.3673\n",
      "Epoch 7\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.3247 - accuracy: 0.1400 - val_loss: 1.3188 - val_accuracy: 0.3673\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.3562 - accuracy: 0.3600 - val_loss: 1.3176 - val_accuracy: 0.3469\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.2871 - accuracy: 0.4000 - val_loss: 1.3159 - val_accuracy: 0.3469\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3536 - accuracy: 0.2600 - val_loss: 1.3136 - val_accuracy: 0.3673\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3823 - accuracy: 0.2400 - val_loss: 1.3118 - val_accuracy: 0.3673\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.2620 - accuracy: 0.5000 - val_loss: 1.3089 - val_accuracy: 0.3980\n",
      "Epoch 8\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.3683 - accuracy: 0.2600 - val_loss: 1.3282 - val_accuracy: 0.3737\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2843 - accuracy: 0.4400 - val_loss: 1.3286 - val_accuracy: 0.3939\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.3893 - accuracy: 0.2857 - val_loss: 1.3226 - val_accuracy: 0.3939\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3861 - accuracy: 0.2800 - val_loss: 1.3246 - val_accuracy: 0.3434\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3375 - accuracy: 0.4400 - val_loss: 1.3355 - val_accuracy: 0.3232\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3587 - accuracy: 0.4000 - val_loss: 1.3411 - val_accuracy: 0.3434\n",
      "Epoch 9\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3499 - accuracy: 0.4400 - val_loss: 1.3600 - val_accuracy: 0.3600\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.3767 - accuracy: 0.4200 - val_loss: 1.3543 - val_accuracy: 0.3800\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.3893 - accuracy: 0.3200 - val_loss: 1.3534 - val_accuracy: 0.3600\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3118 - accuracy: 0.3800 - val_loss: 1.3453 - val_accuracy: 0.3700\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3133 - accuracy: 0.2857 - val_loss: 1.3221 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3444 - accuracy: 0.4200 - val_loss: 1.2958 - val_accuracy: 0.4700\n",
      "Epoch 10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3149 - accuracy: 0.4000 - val_loss: 1.2532 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3747 - accuracy: 0.3800 - val_loss: 1.2826 - val_accuracy: 0.3500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.4565 - accuracy: 0.3400 - val_loss: 1.2912 - val_accuracy: 0.3200\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.4197 - accuracy: 0.2600 - val_loss: 1.2696 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2948 - accuracy: 0.4200 - val_loss: 1.2653 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3176 - accuracy: 0.4400 - val_loss: 1.2693 - val_accuracy: 0.4400\n",
      "Epoch 11\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.3126 - accuracy: 0.3800 - val_loss: 1.2662 - val_accuracy: 0.4433\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.4751 - accuracy: 0.3400 - val_loss: 1.2794 - val_accuracy: 0.4124\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.2866 - accuracy: 0.4600 - val_loss: 1.2822 - val_accuracy: 0.3918\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.3027 - accuracy: 0.3200 - val_loss: 1.2813 - val_accuracy: 0.4021\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3374 - accuracy: 0.3800 - val_loss: 1.2796 - val_accuracy: 0.4021\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3674 - accuracy: 0.4000 - val_loss: 1.2802 - val_accuracy: 0.4124\n",
      "Epoch 12\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2682 - accuracy: 0.4800 - val_loss: 1.2849 - val_accuracy: 0.4124\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2870 - accuracy: 0.4400 - val_loss: 1.2817 - val_accuracy: 0.4124\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.2422 - accuracy: 0.4600 - val_loss: 1.2793 - val_accuracy: 0.3814\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2492 - accuracy: 0.3600 - val_loss: 1.2824 - val_accuracy: 0.4021\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.3894 - accuracy: 0.4200 - val_loss: 1.2794 - val_accuracy: 0.4021\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3328 - accuracy: 0.3200 - val_loss: 1.2820 - val_accuracy: 0.4021\n",
      "Epoch 13\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3576 - accuracy: 0.3400 - val_loss: 1.3408 - val_accuracy: 0.2929\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.3532 - accuracy: 0.2400 - val_loss: 1.3486 - val_accuracy: 0.2929\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3842 - accuracy: 0.3800 - val_loss: 1.3512 - val_accuracy: 0.3131\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3460 - accuracy: 0.3200 - val_loss: 1.3472 - val_accuracy: 0.2929\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.3267 - accuracy: 0.3800 - val_loss: 1.3397 - val_accuracy: 0.2929\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3354 - accuracy: 0.4200 - val_loss: 1.3285 - val_accuracy: 0.3333\n",
      "Epoch 14\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3327 - accuracy: 0.3200 - val_loss: 1.3275 - val_accuracy: 0.3600\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.2490 - accuracy: 0.5000 - val_loss: 1.3239 - val_accuracy: 0.3600\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2703 - accuracy: 0.4600 - val_loss: 1.3251 - val_accuracy: 0.3700\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3390 - accuracy: 0.3200 - val_loss: 1.3262 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3293 - accuracy: 0.4000 - val_loss: 1.3260 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2576 - accuracy: 0.3800 - val_loss: 1.3272 - val_accuracy: 0.3600\n",
      "Epoch 15\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2513 - accuracy: 0.5200 - val_loss: 1.3072 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.2656 - accuracy: 0.4200 - val_loss: 1.3032 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.2305 - accuracy: 0.5400 - val_loss: 1.3049 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3162 - accuracy: 0.4400 - val_loss: 1.3055 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.3974 - accuracy: 0.3600 - val_loss: 1.3098 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2488 - accuracy: 0.4000 - val_loss: 1.3127 - val_accuracy: 0.4400\n",
      "Epoch 16\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2813 - accuracy: 0.4600 - val_loss: 1.2508 - val_accuracy: 0.3711\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2768 - accuracy: 0.3800 - val_loss: 1.2469 - val_accuracy: 0.3608\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2901 - accuracy: 0.4000 - val_loss: 1.2582 - val_accuracy: 0.3711\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3247 - accuracy: 0.3600 - val_loss: 1.2684 - val_accuracy: 0.4021\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2305 - accuracy: 0.3878 - val_loss: 1.2729 - val_accuracy: 0.3814\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2353 - accuracy: 0.4800 - val_loss: 1.2597 - val_accuracy: 0.3608\n",
      "Epoch 17\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3120 - accuracy: 0.4000 - val_loss: 1.2766 - val_accuracy: 0.3608\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2743 - accuracy: 0.5000 - val_loss: 1.2766 - val_accuracy: 0.3711\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2285 - accuracy: 0.5102 - val_loss: 1.2753 - val_accuracy: 0.3402\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2997 - accuracy: 0.3200 - val_loss: 1.2705 - val_accuracy: 0.3814\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2885 - accuracy: 0.4200 - val_loss: 1.2629 - val_accuracy: 0.4021\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.4259 - accuracy: 0.4000 - val_loss: 1.2561 - val_accuracy: 0.4124\n",
      "Epoch 18\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3254 - accuracy: 0.4000 - val_loss: 1.2581 - val_accuracy: 0.4694\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.2349 - accuracy: 0.3800 - val_loss: 1.2606 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.3089 - accuracy: 0.4000 - val_loss: 1.2490 - val_accuracy: 0.4388\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2780 - accuracy: 0.5102 - val_loss: 1.2453 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2180 - accuracy: 0.3800 - val_loss: 1.2448 - val_accuracy: 0.4082\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3352 - accuracy: 0.3000 - val_loss: 1.2440 - val_accuracy: 0.3980\n",
      "Epoch 19\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2940 - accuracy: 0.4000 - val_loss: 1.2468 - val_accuracy: 0.4082\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2621 - accuracy: 0.4200 - val_loss: 1.2466 - val_accuracy: 0.4082\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3081 - accuracy: 0.3600 - val_loss: 1.2452 - val_accuracy: 0.4082\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2434 - accuracy: 0.4800 - val_loss: 1.2434 - val_accuracy: 0.4184\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3615 - accuracy: 0.4000 - val_loss: 1.2445 - val_accuracy: 0.4082\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2841 - accuracy: 0.4000 - val_loss: 1.2420 - val_accuracy: 0.4082\n",
      "Epoch 20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.2442 - accuracy: 0.3400 - val_loss: 1.2663 - val_accuracy: 0.3402\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2660 - accuracy: 0.4200 - val_loss: 1.2707 - val_accuracy: 0.3711\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2306 - accuracy: 0.5600 - val_loss: 1.2716 - val_accuracy: 0.4227\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2168 - accuracy: 0.4000 - val_loss: 1.2699 - val_accuracy: 0.4330\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.3051 - accuracy: 0.4286 - val_loss: 1.2642 - val_accuracy: 0.4433\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.3881 - accuracy: 0.3000 - val_loss: 1.2599 - val_accuracy: 0.4124\n",
      "Epoch 21\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.2277 - accuracy: 0.3878 - val_loss: 1.2325 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2873 - accuracy: 0.4400 - val_loss: 1.2290 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3193 - accuracy: 0.4400 - val_loss: 1.2305 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2553 - accuracy: 0.4000 - val_loss: 1.2401 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2180 - accuracy: 0.4600 - val_loss: 1.2536 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.3323 - accuracy: 0.4000 - val_loss: 1.2706 - val_accuracy: 0.3800\n",
      "Epoch 22\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3103 - accuracy: 0.3600 - val_loss: 1.2461 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.5182 - accuracy: 0.3200 - val_loss: 1.2341 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3036 - accuracy: 0.3400 - val_loss: 1.2443 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2447 - accuracy: 0.4000 - val_loss: 1.2570 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2741 - accuracy: 0.4400 - val_loss: 1.2614 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2591 - accuracy: 0.4200 - val_loss: 1.2633 - val_accuracy: 0.4700\n",
      "Epoch 23\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1989 - accuracy: 0.4898 - val_loss: 1.2320 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2351 - accuracy: 0.5200 - val_loss: 1.2195 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2440 - accuracy: 0.5200 - val_loss: 1.2203 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.3201 - accuracy: 0.2800 - val_loss: 1.2195 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2120 - accuracy: 0.3000 - val_loss: 1.2175 - val_accuracy: 0.4592\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1790 - accuracy: 0.4600 - val_loss: 1.2165 - val_accuracy: 0.4694\n",
      "Epoch 24\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3490 - accuracy: 0.4200 - val_loss: 1.2231 - val_accuracy: 0.4330\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2876 - accuracy: 0.3400 - val_loss: 1.2132 - val_accuracy: 0.4227\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2872 - accuracy: 0.4000 - val_loss: 1.2120 - val_accuracy: 0.4639\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1334 - accuracy: 0.5800 - val_loss: 1.2121 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1982 - accuracy: 0.4898 - val_loss: 1.1998 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2987 - accuracy: 0.3800 - val_loss: 1.1943 - val_accuracy: 0.4845\n",
      "Epoch 25\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.1743 - accuracy: 0.5200 - val_loss: 1.2232 - val_accuracy: 0.4343\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1758 - accuracy: 0.4200 - val_loss: 1.2391 - val_accuracy: 0.4444\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2112 - accuracy: 0.4200 - val_loss: 1.2300 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3204 - accuracy: 0.3600 - val_loss: 1.2194 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1849 - accuracy: 0.5400 - val_loss: 1.2162 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2996 - accuracy: 0.3400 - val_loss: 1.2149 - val_accuracy: 0.4747\n",
      "Epoch 26\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1618 - accuracy: 0.5400 - val_loss: 1.1724 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1564 - accuracy: 0.5200 - val_loss: 1.1794 - val_accuracy: 0.4898\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2289 - accuracy: 0.4200 - val_loss: 1.1773 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1502 - accuracy: 0.5800 - val_loss: 1.1791 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.3077 - accuracy: 0.3800 - val_loss: 1.1801 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2563 - accuracy: 0.3400 - val_loss: 1.1800 - val_accuracy: 0.4490\n",
      "Epoch 27\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.1599 - accuracy: 0.4600 - val_loss: 1.1804 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1386 - accuracy: 0.5000 - val_loss: 1.1788 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1962 - accuracy: 0.4000 - val_loss: 1.1826 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2300 - accuracy: 0.4200 - val_loss: 1.1842 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2689 - accuracy: 0.3000 - val_loss: 1.1896 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2088 - accuracy: 0.5000 - val_loss: 1.1912 - val_accuracy: 0.5200\n",
      "Epoch 28\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.1476 - accuracy: 0.4600 - val_loss: 1.2235 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2154 - accuracy: 0.5000 - val_loss: 1.2383 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2113 - accuracy: 0.4000 - val_loss: 1.2622 - val_accuracy: 0.4343\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2289 - accuracy: 0.4400 - val_loss: 1.2417 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2653 - accuracy: 0.4600 - val_loss: 1.2085 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1978 - accuracy: 0.5000 - val_loss: 1.1840 - val_accuracy: 0.5152\n",
      "Epoch 29\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2434 - accuracy: 0.4400 - val_loss: 1.2134 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.2659 - accuracy: 0.4000 - val_loss: 1.2200 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1964 - accuracy: 0.4800 - val_loss: 1.2141 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3482 - accuracy: 0.3800 - val_loss: 1.1989 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1223 - accuracy: 0.5400 - val_loss: 1.1970 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0809 - accuracy: 0.4400 - val_loss: 1.1989 - val_accuracy: 0.4900\n",
      "Epoch 30\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3051 - accuracy: 0.4400 - val_loss: 1.1876 - val_accuracy: 0.4639\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3593 - accuracy: 0.4600 - val_loss: 1.1766 - val_accuracy: 0.4742\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1587 - accuracy: 0.4898 - val_loss: 1.1898 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.1642 - accuracy: 0.6200 - val_loss: 1.1995 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2389 - accuracy: 0.3800 - val_loss: 1.2024 - val_accuracy: 0.4639\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2909 - accuracy: 0.3200 - val_loss: 1.2026 - val_accuracy: 0.4021\n",
      "Epoch 31\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.1899 - accuracy: 0.4800 - val_loss: 1.2114 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.2335 - accuracy: 0.3400 - val_loss: 1.2247 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.3384 - accuracy: 0.3400 - val_loss: 1.2270 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1399 - accuracy: 0.5600 - val_loss: 1.2054 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3029 - accuracy: 0.4600 - val_loss: 1.1791 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2066 - accuracy: 0.4000 - val_loss: 1.1837 - val_accuracy: 0.4500\n",
      "Epoch 32\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.2567 - accuracy: 0.4400 - val_loss: 1.1974 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2260 - accuracy: 0.4286 - val_loss: 1.2018 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2268 - accuracy: 0.4400 - val_loss: 1.2046 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.3018 - accuracy: 0.4200 - val_loss: 1.2012 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2434 - accuracy: 0.4000 - val_loss: 1.2044 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1605 - accuracy: 0.4400 - val_loss: 1.2050 - val_accuracy: 0.4700\n",
      "Epoch 33\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2229 - accuracy: 0.4200 - val_loss: 1.2466 - val_accuracy: 0.3838\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1781 - accuracy: 0.5200 - val_loss: 1.2683 - val_accuracy: 0.3737\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2129 - accuracy: 0.4400 - val_loss: 1.2643 - val_accuracy: 0.3737\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2088 - accuracy: 0.4600 - val_loss: 1.2545 - val_accuracy: 0.3838\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1923 - accuracy: 0.5102 - val_loss: 1.2280 - val_accuracy: 0.3939\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.4026 - accuracy: 0.3800 - val_loss: 1.2110 - val_accuracy: 0.4545\n",
      "Epoch 34\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1289 - accuracy: 0.5800 - val_loss: 1.1464 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.3314 - accuracy: 0.4200 - val_loss: 1.1530 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2811 - accuracy: 0.3400 - val_loss: 1.1511 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1995 - accuracy: 0.4400 - val_loss: 1.1382 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.2657 - accuracy: 0.3600 - val_loss: 1.1355 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2229 - accuracy: 0.5800 - val_loss: 1.1250 - val_accuracy: 0.5567\n",
      "Epoch 35\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1047 - accuracy: 0.5200 - val_loss: 1.1589 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2413 - accuracy: 0.3400 - val_loss: 1.1447 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.2205 - accuracy: 0.5800 - val_loss: 1.1376 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2542 - accuracy: 0.5000 - val_loss: 1.1424 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0801 - accuracy: 0.5000 - val_loss: 1.1477 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2208 - accuracy: 0.4200 - val_loss: 1.1599 - val_accuracy: 0.4900\n",
      "Epoch 36\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2869 - accuracy: 0.4600 - val_loss: 1.1685 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1738 - accuracy: 0.4400 - val_loss: 1.1637 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1732 - accuracy: 0.5200 - val_loss: 1.1665 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2875 - accuracy: 0.2400 - val_loss: 1.1721 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 261ms/step - loss: 1.4029 - accuracy: 0.2800 - val_loss: 1.1755 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2420 - accuracy: 0.3600 - val_loss: 1.1756 - val_accuracy: 0.5556\n",
      "Epoch 37\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2294 - accuracy: 0.5000 - val_loss: 1.1626 - val_accuracy: 0.4845\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2421 - accuracy: 0.3400 - val_loss: 1.1490 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1854 - accuracy: 0.4082 - val_loss: 1.1410 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2465 - accuracy: 0.4000 - val_loss: 1.1384 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0392 - accuracy: 0.5200 - val_loss: 1.1689 - val_accuracy: 0.4742\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3164 - accuracy: 0.3800 - val_loss: 1.1443 - val_accuracy: 0.4639\n",
      "Epoch 38\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2022 - accuracy: 0.4400 - val_loss: 1.1610 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1695 - accuracy: 0.4600 - val_loss: 1.1582 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1922 - accuracy: 0.5200 - val_loss: 1.1562 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1412 - accuracy: 0.5000 - val_loss: 1.1537 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1823 - accuracy: 0.5600 - val_loss: 1.1493 - val_accuracy: 0.5102\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.3623 - accuracy: 0.2800 - val_loss: 1.1410 - val_accuracy: 0.5102\n",
      "Epoch 39\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1787 - accuracy: 0.5400 - val_loss: 1.1254 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0706 - accuracy: 0.4600 - val_loss: 1.1414 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.2529 - accuracy: 0.4200 - val_loss: 1.1620 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2246 - accuracy: 0.3800 - val_loss: 1.1851 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3748 - accuracy: 0.4400 - val_loss: 1.1529 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2317 - accuracy: 0.4400 - val_loss: 1.1297 - val_accuracy: 0.5354\n",
      "Epoch 40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1906 - accuracy: 0.4800 - val_loss: 1.1653 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2020 - accuracy: 0.5000 - val_loss: 1.1552 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.3658 - accuracy: 0.3200 - val_loss: 1.1096 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1902 - accuracy: 0.4898 - val_loss: 1.0940 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2674 - accuracy: 0.3800 - val_loss: 1.1119 - val_accuracy: 0.4536\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.5156 - accuracy: 0.4600 - val_loss: 1.1013 - val_accuracy: 0.4639\n",
      "Epoch 41\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2518 - accuracy: 0.4286 - val_loss: 1.2935 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.0227 - accuracy: 0.5800 - val_loss: 1.2917 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.1965 - accuracy: 0.4400 - val_loss: 1.2997 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.3842 - accuracy: 0.4200 - val_loss: 1.3026 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1977 - accuracy: 0.4800 - val_loss: 1.3011 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0757 - accuracy: 0.5200 - val_loss: 1.2913 - val_accuracy: 0.3800\n",
      "Epoch 42\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3080 - accuracy: 0.3200 - val_loss: 1.1254 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2865 - accuracy: 0.4200 - val_loss: 1.1429 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2466 - accuracy: 0.4600 - val_loss: 1.1582 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1406 - accuracy: 0.4600 - val_loss: 1.1755 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1452 - accuracy: 0.4600 - val_loss: 1.1948 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3161 - accuracy: 0.3600 - val_loss: 1.2035 - val_accuracy: 0.4400\n",
      "Epoch 43\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.3799 - accuracy: 0.3673 - val_loss: 1.1021 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0895 - accuracy: 0.5800 - val_loss: 1.0871 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2009 - accuracy: 0.4800 - val_loss: 1.0963 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1435 - accuracy: 0.4400 - val_loss: 1.1034 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3239 - accuracy: 0.3200 - val_loss: 1.1020 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2508 - accuracy: 0.4600 - val_loss: 1.1004 - val_accuracy: 0.5258\n",
      "Epoch 44\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1735 - accuracy: 0.4400 - val_loss: 1.0898 - val_accuracy: 0.5155\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2559 - accuracy: 0.4600 - val_loss: 1.0861 - val_accuracy: 0.5155\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1019 - accuracy: 0.5000 - val_loss: 1.0868 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2211 - accuracy: 0.4400 - val_loss: 1.1081 - val_accuracy: 0.4639\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2862 - accuracy: 0.3400 - val_loss: 1.1687 - val_accuracy: 0.4227\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1986 - accuracy: 0.4800 - val_loss: 1.1825 - val_accuracy: 0.4227\n",
      "Epoch 45\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2497 - accuracy: 0.3800 - val_loss: 1.1720 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2358 - accuracy: 0.4800 - val_loss: 1.1655 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1755 - accuracy: 0.5200 - val_loss: 1.1684 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3420 - accuracy: 0.3400 - val_loss: 1.1765 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1725 - accuracy: 0.4800 - val_loss: 1.1842 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1305 - accuracy: 0.4600 - val_loss: 1.1851 - val_accuracy: 0.5000\n",
      "Epoch 46\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.2562 - accuracy: 0.4800 - val_loss: 1.1475 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1922 - accuracy: 0.4400 - val_loss: 1.1371 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1066 - accuracy: 0.5510 - val_loss: 1.1286 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2980 - accuracy: 0.4000 - val_loss: 1.1254 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1499 - accuracy: 0.4600 - val_loss: 1.1236 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3026 - accuracy: 0.3400 - val_loss: 1.1209 - val_accuracy: 0.4646\n",
      "Epoch 47\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0724 - accuracy: 0.6000 - val_loss: 1.1140 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2978 - accuracy: 0.3061 - val_loss: 1.1288 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.2201 - accuracy: 0.3800 - val_loss: 1.1373 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1766 - accuracy: 0.4200 - val_loss: 1.1339 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2064 - accuracy: 0.3800 - val_loss: 1.1239 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1572 - accuracy: 0.4600 - val_loss: 1.1102 - val_accuracy: 0.5253\n",
      "Epoch 48\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.1446 - accuracy: 0.5000 - val_loss: 1.0590 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1121 - accuracy: 0.5400 - val_loss: 1.0567 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2953 - accuracy: 0.4600 - val_loss: 1.0725 - val_accuracy: 0.4742\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0917 - accuracy: 0.5400 - val_loss: 1.0874 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.4009 - accuracy: 0.4082 - val_loss: 1.0770 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1521 - accuracy: 0.4200 - val_loss: 1.0686 - val_accuracy: 0.4948\n",
      "Epoch 49\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1512 - accuracy: 0.4000 - val_loss: 1.2098 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2322 - accuracy: 0.4400 - val_loss: 1.2107 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2482 - accuracy: 0.4600 - val_loss: 1.2110 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2287 - accuracy: 0.4800 - val_loss: 1.2058 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1909 - accuracy: 0.4400 - val_loss: 1.2131 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1021 - accuracy: 0.5306 - val_loss: 1.2245 - val_accuracy: 0.4700\n",
      "Epoch 50\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1389 - accuracy: 0.4200 - val_loss: 1.1124 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0137 - accuracy: 0.5306 - val_loss: 1.1165 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2351 - accuracy: 0.4000 - val_loss: 1.1344 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2698 - accuracy: 0.3800 - val_loss: 1.1509 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3182 - accuracy: 0.3400 - val_loss: 1.1560 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0781 - accuracy: 0.6400 - val_loss: 1.1455 - val_accuracy: 0.4800\n",
      "Epoch 51\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1577 - accuracy: 0.5400 - val_loss: 1.0949 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1974 - accuracy: 0.4400 - val_loss: 1.0972 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2683 - accuracy: 0.3600 - val_loss: 1.1051 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2368 - accuracy: 0.4200 - val_loss: 1.1140 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2020 - accuracy: 0.4000 - val_loss: 1.1187 - val_accuracy: 0.4949\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1926 - accuracy: 0.4200 - val_loss: 1.1228 - val_accuracy: 0.4848\n",
      "Epoch 52\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2254 - accuracy: 0.4200 - val_loss: 1.1258 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.1032 - accuracy: 0.5400 - val_loss: 1.1275 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2926 - accuracy: 0.3400 - val_loss: 1.1183 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1749 - accuracy: 0.5000 - val_loss: 1.1061 - val_accuracy: 0.5155\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.3346 - accuracy: 0.2800 - val_loss: 1.0962 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1652 - accuracy: 0.5102 - val_loss: 1.0876 - val_accuracy: 0.5155\n",
      "Epoch 53\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1231 - accuracy: 0.5000 - val_loss: 1.1425 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1519 - accuracy: 0.5510 - val_loss: 1.1438 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1355 - accuracy: 0.5000 - val_loss: 1.1396 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1657 - accuracy: 0.4000 - val_loss: 1.1370 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0855 - accuracy: 0.5200 - val_loss: 1.1296 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1334 - accuracy: 0.3600 - val_loss: 1.1213 - val_accuracy: 0.5200\n",
      "Epoch 54\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1245 - accuracy: 0.5000 - val_loss: 1.0295 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0696 - accuracy: 0.5800 - val_loss: 1.0280 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2278 - accuracy: 0.4600 - val_loss: 1.0296 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1650 - accuracy: 0.4600 - val_loss: 1.0271 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3344 - accuracy: 0.3200 - val_loss: 1.0248 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.9841 - accuracy: 0.6400 - val_loss: 1.0312 - val_accuracy: 0.5258\n",
      "Epoch 55\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.0452 - accuracy: 0.5510 - val_loss: 1.0603 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2314 - accuracy: 0.4600 - val_loss: 1.0588 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0187 - accuracy: 0.5400 - val_loss: 1.0545 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1409 - accuracy: 0.5200 - val_loss: 1.0683 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.3165 - accuracy: 0.3600 - val_loss: 1.0763 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0585 - accuracy: 0.5200 - val_loss: 1.0530 - val_accuracy: 0.5155\n",
      "Epoch 56\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1491 - accuracy: 0.4400 - val_loss: 1.1164 - val_accuracy: 0.5657\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2177 - accuracy: 0.4600 - val_loss: 1.1205 - val_accuracy: 0.5657\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 1.1376 - accuracy: 0.4800 - val_loss: 1.1448 - val_accuracy: 0.5758\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1644 - accuracy: 0.5800 - val_loss: 1.1808 - val_accuracy: 0.5051\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0338 - accuracy: 0.5000 - val_loss: 1.1840 - val_accuracy: 0.4646\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1305 - accuracy: 0.4200 - val_loss: 1.1819 - val_accuracy: 0.4848\n",
      "Epoch 57\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.3079 - accuracy: 0.4800 - val_loss: 1.2111 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2597 - accuracy: 0.4400 - val_loss: 1.2033 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1942 - accuracy: 0.4400 - val_loss: 1.2128 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2708 - accuracy: 0.4000 - val_loss: 1.2042 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3034 - accuracy: 0.3800 - val_loss: 1.1954 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1422 - accuracy: 0.4600 - val_loss: 1.2135 - val_accuracy: 0.4400\n",
      "Epoch 58\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0424 - accuracy: 0.5600 - val_loss: 1.2264 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1443 - accuracy: 0.4600 - val_loss: 1.2698 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2674 - accuracy: 0.3600 - val_loss: 1.2557 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2592 - accuracy: 0.4600 - val_loss: 1.2203 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2463 - accuracy: 0.4600 - val_loss: 1.1769 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0853 - accuracy: 0.5000 - val_loss: 1.1746 - val_accuracy: 0.5000\n",
      "Epoch 59\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1411 - accuracy: 0.5200 - val_loss: 1.1197 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2196 - accuracy: 0.4375 - val_loss: 1.1295 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1927 - accuracy: 0.3800 - val_loss: 1.1316 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.1225 - accuracy: 0.4600 - val_loss: 1.1312 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.1259 - accuracy: 0.4694 - val_loss: 1.1294 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1874 - accuracy: 0.4400 - val_loss: 1.1248 - val_accuracy: 0.5200\n",
      "Epoch 60\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1064 - accuracy: 0.5000 - val_loss: 1.0540 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1359 - accuracy: 0.4800 - val_loss: 1.0658 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2487 - accuracy: 0.3800 - val_loss: 1.1013 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2737 - accuracy: 0.4800 - val_loss: 1.1076 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1700 - accuracy: 0.4800 - val_loss: 1.0957 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2075 - accuracy: 0.3265 - val_loss: 1.0912 - val_accuracy: 0.5204\n",
      "Epoch 61\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0726 - accuracy: 0.5000 - val_loss: 1.1735 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1931 - accuracy: 0.4200 - val_loss: 1.1827 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2360 - accuracy: 0.4200 - val_loss: 1.1837 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1722 - accuracy: 0.4600 - val_loss: 1.1808 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1716 - accuracy: 0.4000 - val_loss: 1.1763 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1187 - accuracy: 0.5800 - val_loss: 1.1844 - val_accuracy: 0.4600\n",
      "Epoch 62\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1811 - accuracy: 0.4000 - val_loss: 1.0682 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0906 - accuracy: 0.5400 - val_loss: 1.0593 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1143 - accuracy: 0.5400 - val_loss: 1.0531 - val_accuracy: 0.5408\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0848 - accuracy: 0.5400 - val_loss: 1.0464 - val_accuracy: 0.5612\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0373 - accuracy: 0.5000 - val_loss: 1.0398 - val_accuracy: 0.5714\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.0594 - accuracy: 0.4490 - val_loss: 1.0294 - val_accuracy: 0.5816\n",
      "Epoch 63\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.0408 - accuracy: 0.5600 - val_loss: 1.0427 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1013 - accuracy: 0.5200 - val_loss: 1.0260 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0349 - accuracy: 0.5400 - val_loss: 1.0253 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0533 - accuracy: 0.5200 - val_loss: 1.0188 - val_accuracy: 0.5155\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1559 - accuracy: 0.4694 - val_loss: 1.0163 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1633 - accuracy: 0.4400 - val_loss: 1.0218 - val_accuracy: 0.5258\n",
      "Epoch 64\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1497 - accuracy: 0.5000 - val_loss: 1.0068 - val_accuracy: 0.5876\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1974 - accuracy: 0.5000 - val_loss: 1.0189 - val_accuracy: 0.5979\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0024 - accuracy: 0.4800 - val_loss: 1.0164 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.9526 - accuracy: 0.6600 - val_loss: 0.9858 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1891 - accuracy: 0.5200 - val_loss: 0.9789 - val_accuracy: 0.5670\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1163 - accuracy: 0.4800 - val_loss: 0.9894 - val_accuracy: 0.5876\n",
      "Epoch 65\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3128 - accuracy: 0.4000 - val_loss: 1.1059 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1689 - accuracy: 0.4000 - val_loss: 1.1008 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3025 - accuracy: 0.2800 - val_loss: 1.1021 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1355 - accuracy: 0.5600 - val_loss: 1.1048 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1840 - accuracy: 0.4600 - val_loss: 1.1080 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2074 - accuracy: 0.4800 - val_loss: 1.1125 - val_accuracy: 0.4900\n",
      "Epoch 66\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0728 - accuracy: 0.4800 - val_loss: 1.1309 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0674 - accuracy: 0.5600 - val_loss: 1.1275 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2151 - accuracy: 0.4000 - val_loss: 1.1253 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1808 - accuracy: 0.3400 - val_loss: 1.1208 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0769 - accuracy: 0.4600 - val_loss: 1.1252 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1248 - accuracy: 0.5200 - val_loss: 1.1156 - val_accuracy: 0.4747\n",
      "Epoch 67\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.2141 - accuracy: 0.3800 - val_loss: 1.1226 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.9945 - accuracy: 0.5510 - val_loss: 1.1332 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1063 - accuracy: 0.4600 - val_loss: 1.1342 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.0957 - accuracy: 0.4600 - val_loss: 1.1394 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.0405 - accuracy: 0.5000 - val_loss: 1.1431 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2817 - accuracy: 0.4600 - val_loss: 1.1349 - val_accuracy: 0.5700\n",
      "Epoch 68\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.2348 - accuracy: 0.4400 - val_loss: 1.0209 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.9766 - accuracy: 0.6531 - val_loss: 1.0459 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0382 - accuracy: 0.5000 - val_loss: 1.0724 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1299 - accuracy: 0.5400 - val_loss: 1.0802 - val_accuracy: 0.5670\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1499 - accuracy: 0.4600 - val_loss: 1.0844 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2768 - accuracy: 0.4000 - val_loss: 1.0897 - val_accuracy: 0.5670\n",
      "Epoch 69\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1322 - accuracy: 0.5000 - val_loss: 1.1697 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0648 - accuracy: 0.5000 - val_loss: 1.1717 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2015 - accuracy: 0.4000 - val_loss: 1.1734 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1667 - accuracy: 0.4400 - val_loss: 1.1714 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0043 - accuracy: 0.6400 - val_loss: 1.1720 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0128 - accuracy: 0.5800 - val_loss: 1.1731 - val_accuracy: 0.5100\n",
      "Epoch 70\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0633 - accuracy: 0.4800 - val_loss: 1.0522 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1394 - accuracy: 0.4600 - val_loss: 1.0208 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0889 - accuracy: 0.5200 - val_loss: 1.0115 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2858 - accuracy: 0.4600 - val_loss: 1.0140 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0956 - accuracy: 0.4400 - val_loss: 1.0318 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0502 - accuracy: 0.5600 - val_loss: 1.0573 - val_accuracy: 0.5464\n",
      "Epoch 71\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.0083 - accuracy: 0.5200 - val_loss: 1.0522 - val_accuracy: 0.5312\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.3029 - accuracy: 0.4200 - val_loss: 1.0335 - val_accuracy: 0.5104\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1902 - accuracy: 0.4000 - val_loss: 1.0177 - val_accuracy: 0.5104\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0459 - accuracy: 0.4898 - val_loss: 1.0141 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1674 - accuracy: 0.5000 - val_loss: 1.0130 - val_accuracy: 0.5625\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1686 - accuracy: 0.4600 - val_loss: 1.0156 - val_accuracy: 0.5729\n",
      "Epoch 72\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3618 - accuracy: 0.3400 - val_loss: 1.1100 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.9945 - accuracy: 0.6000 - val_loss: 1.1040 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1062 - accuracy: 0.5600 - val_loss: 1.1019 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1315 - accuracy: 0.4600 - val_loss: 1.1036 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1433 - accuracy: 0.4400 - val_loss: 1.1009 - val_accuracy: 0.5400\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1734 - accuracy: 0.4400 - val_loss: 1.0854 - val_accuracy: 0.4900\n",
      "Epoch 73\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.0990 - accuracy: 0.5600 - val_loss: 1.0500 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0278 - accuracy: 0.5600 - val_loss: 1.0434 - val_accuracy: 0.5670\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1917 - accuracy: 0.4400 - val_loss: 1.0169 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1878 - accuracy: 0.5000 - val_loss: 1.0145 - val_accuracy: 0.5876\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2893 - accuracy: 0.4400 - val_loss: 1.0374 - val_accuracy: 0.5876\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1815 - accuracy: 0.4200 - val_loss: 1.0707 - val_accuracy: 0.5773\n",
      "Epoch 74\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2427 - accuracy: 0.4400 - val_loss: 1.0914 - val_accuracy: 0.5979\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9455 - accuracy: 0.6327 - val_loss: 1.0979 - val_accuracy: 0.5670\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1287 - accuracy: 0.4400 - val_loss: 1.0942 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1942 - accuracy: 0.4200 - val_loss: 1.0898 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1356 - accuracy: 0.5200 - val_loss: 1.0867 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0466 - accuracy: 0.5000 - val_loss: 1.0849 - val_accuracy: 0.5567\n",
      "Epoch 75\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0968 - accuracy: 0.5200 - val_loss: 1.0412 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0175 - accuracy: 0.6400 - val_loss: 1.0407 - val_accuracy: 0.5052\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2475 - accuracy: 0.3600 - val_loss: 1.0421 - val_accuracy: 0.5155\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.9833 - accuracy: 0.5600 - val_loss: 1.0395 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1750 - accuracy: 0.5400 - val_loss: 1.0224 - val_accuracy: 0.5670\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1562 - accuracy: 0.4600 - val_loss: 1.0033 - val_accuracy: 0.5876\n",
      "Epoch 76\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.9464 - accuracy: 0.6200 - val_loss: 1.0126 - val_accuracy: 0.5918\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1611 - accuracy: 0.4400 - val_loss: 1.0110 - val_accuracy: 0.5510\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1018 - accuracy: 0.4286 - val_loss: 1.0131 - val_accuracy: 0.5612\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1466 - accuracy: 0.5000 - val_loss: 1.0057 - val_accuracy: 0.6020\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1228 - accuracy: 0.5000 - val_loss: 1.0123 - val_accuracy: 0.6020\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1073 - accuracy: 0.4200 - val_loss: 1.0587 - val_accuracy: 0.5510\n",
      "Epoch 77\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3976 - accuracy: 0.3400 - val_loss: 1.2227 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0646 - accuracy: 0.5600 - val_loss: 1.2210 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1027 - accuracy: 0.5600 - val_loss: 1.1677 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1116 - accuracy: 0.4800 - val_loss: 1.1553 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0979 - accuracy: 0.4490 - val_loss: 1.1653 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1167 - accuracy: 0.5400 - val_loss: 1.1877 - val_accuracy: 0.5000\n",
      "Epoch 78\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1930 - accuracy: 0.5400 - val_loss: 1.0377 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3760 - accuracy: 0.3200 - val_loss: 1.0276 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1573 - accuracy: 0.4000 - val_loss: 1.0376 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0724 - accuracy: 0.4898 - val_loss: 1.0677 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1649 - accuracy: 0.5400 - val_loss: 1.0892 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.0670 - accuracy: 0.5000 - val_loss: 1.0843 - val_accuracy: 0.5258\n",
      "Epoch 79\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2405 - accuracy: 0.4000 - val_loss: 1.1394 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1279 - accuracy: 0.4800 - val_loss: 1.1442 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2712 - accuracy: 0.4400 - val_loss: 1.1418 - val_accuracy: 0.4800\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1093 - accuracy: 0.4800 - val_loss: 1.1368 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1418 - accuracy: 0.4200 - val_loss: 1.1328 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2917 - accuracy: 0.5200 - val_loss: 1.1270 - val_accuracy: 0.4600\n",
      "Epoch 80\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1161 - accuracy: 0.4800 - val_loss: 1.1370 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2023 - accuracy: 0.5000 - val_loss: 1.0865 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0872 - accuracy: 0.3800 - val_loss: 1.1002 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1640 - accuracy: 0.4200 - val_loss: 1.1112 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2538 - accuracy: 0.4200 - val_loss: 1.0741 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2024 - accuracy: 0.4800 - val_loss: 1.0653 - val_accuracy: 0.5300\n",
      "Epoch 81\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1151 - accuracy: 0.5400 - val_loss: 1.0762 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0952 - accuracy: 0.4800 - val_loss: 1.1168 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1653 - accuracy: 0.4600 - val_loss: 1.0525 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0402 - accuracy: 0.5800 - val_loss: 0.9974 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1552 - accuracy: 0.4800 - val_loss: 0.9888 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3691 - accuracy: 0.3200 - val_loss: 1.0091 - val_accuracy: 0.5773\n",
      "Epoch 82\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1988 - accuracy: 0.4200 - val_loss: 1.0375 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0040 - accuracy: 0.5400 - val_loss: 1.0495 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.2404 - accuracy: 0.4600 - val_loss: 1.0468 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1770 - accuracy: 0.5000 - val_loss: 1.0385 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1876 - accuracy: 0.4400 - val_loss: 1.0344 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1824 - accuracy: 0.4600 - val_loss: 1.0431 - val_accuracy: 0.5258\n",
      "Epoch 83\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1463 - accuracy: 0.4600 - val_loss: 1.2219 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1640 - accuracy: 0.4800 - val_loss: 1.2306 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2546 - accuracy: 0.4800 - val_loss: 1.2501 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.0804 - accuracy: 0.6000 - val_loss: 1.2640 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.3515 - accuracy: 0.4490 - val_loss: 1.2482 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2705 - accuracy: 0.3800 - val_loss: 1.2348 - val_accuracy: 0.4400\n",
      "Epoch 84\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1040 - accuracy: 0.4800 - val_loss: 1.1390 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0452 - accuracy: 0.5200 - val_loss: 1.1499 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0263 - accuracy: 0.5600 - val_loss: 1.1559 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1210 - accuracy: 0.4898 - val_loss: 1.1524 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1308 - accuracy: 0.5000 - val_loss: 1.1506 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0893 - accuracy: 0.4600 - val_loss: 1.1441 - val_accuracy: 0.5300\n",
      "Epoch 85\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1311 - accuracy: 0.5200 - val_loss: 1.0793 - val_accuracy: 0.4792\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1853 - accuracy: 0.4000 - val_loss: 1.0540 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1264 - accuracy: 0.3878 - val_loss: 1.0365 - val_accuracy: 0.5104\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1423 - accuracy: 0.5400 - val_loss: 1.0430 - val_accuracy: 0.4896\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1918 - accuracy: 0.5800 - val_loss: 1.0531 - val_accuracy: 0.4792\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9307 - accuracy: 0.5200 - val_loss: 1.0669 - val_accuracy: 0.4896\n",
      "Epoch 86\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1426 - accuracy: 0.4600 - val_loss: 1.1542 - val_accuracy: 0.4742\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2463 - accuracy: 0.3800 - val_loss: 1.1443 - val_accuracy: 0.4639\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0774 - accuracy: 0.5200 - val_loss: 1.1190 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0003 - accuracy: 0.5102 - val_loss: 1.0985 - val_accuracy: 0.4845\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0189 - accuracy: 0.5600 - val_loss: 1.0959 - val_accuracy: 0.4845\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.2206 - accuracy: 0.4400 - val_loss: 1.0894 - val_accuracy: 0.4948\n",
      "Epoch 87\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0162 - accuracy: 0.5510 - val_loss: 1.1574 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2698 - accuracy: 0.4400 - val_loss: 1.1550 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.9803 - accuracy: 0.5200 - val_loss: 1.1524 - val_accuracy: 0.5100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1403 - accuracy: 0.4600 - val_loss: 1.1414 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.1253 - accuracy: 0.4200 - val_loss: 1.1358 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0582 - accuracy: 0.5000 - val_loss: 1.1503 - val_accuracy: 0.5000\n",
      "Epoch 88\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0749 - accuracy: 0.5200 - val_loss: 1.1134 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.9879 - accuracy: 0.5200 - val_loss: 1.1069 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.0030 - accuracy: 0.5400 - val_loss: 1.0994 - val_accuracy: 0.5455\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.3164 - accuracy: 0.4800 - val_loss: 1.1056 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.9895 - accuracy: 0.5714 - val_loss: 1.1265 - val_accuracy: 0.4545\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0612 - accuracy: 0.5600 - val_loss: 1.1026 - val_accuracy: 0.4646\n",
      "Epoch 89\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3824 - accuracy: 0.3800 - val_loss: 1.2215 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0628 - accuracy: 0.5600 - val_loss: 1.2265 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.1751 - accuracy: 0.4400 - val_loss: 1.2273 - val_accuracy: 0.4100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0942 - accuracy: 0.5200 - val_loss: 1.2248 - val_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1294 - accuracy: 0.5000 - val_loss: 1.2169 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2135 - accuracy: 0.4000 - val_loss: 1.2112 - val_accuracy: 0.4600\n",
      "Epoch 90\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1105 - accuracy: 0.3800 - val_loss: 0.9765 - val_accuracy: 0.5567\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0988 - accuracy: 0.4400 - val_loss: 0.9801 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.0723 - accuracy: 0.4600 - val_loss: 0.9834 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0772 - accuracy: 0.4800 - val_loss: 0.9854 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2889 - accuracy: 0.4000 - val_loss: 0.9829 - val_accuracy: 0.5464\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.9876 - accuracy: 0.5200 - val_loss: 0.9765 - val_accuracy: 0.5670\n",
      "Epoch 91\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1450 - accuracy: 0.4600 - val_loss: 1.0834 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0028 - accuracy: 0.5400 - val_loss: 1.0847 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0965 - accuracy: 0.5102 - val_loss: 1.0594 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0913 - accuracy: 0.4000 - val_loss: 1.0385 - val_accuracy: 0.5800\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.0309 - accuracy: 0.6000 - val_loss: 1.0275 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1843 - accuracy: 0.4600 - val_loss: 1.0209 - val_accuracy: 0.5500\n",
      "Epoch 92\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1366 - accuracy: 0.4800 - val_loss: 0.9856 - val_accuracy: 0.6289\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1231 - accuracy: 0.5000 - val_loss: 0.9903 - val_accuracy: 0.6082\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.2071 - accuracy: 0.5800 - val_loss: 0.9929 - val_accuracy: 0.5979\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2356 - accuracy: 0.4200 - val_loss: 1.0227 - val_accuracy: 0.5773\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1496 - accuracy: 0.5200 - val_loss: 1.0602 - val_accuracy: 0.5155\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2249 - accuracy: 0.4400 - val_loss: 1.0812 - val_accuracy: 0.5052\n",
      "Epoch 93\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1223 - accuracy: 0.4694 - val_loss: 1.0918 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.9577 - accuracy: 0.6600 - val_loss: 1.1059 - val_accuracy: 0.5361\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1534 - accuracy: 0.4200 - val_loss: 1.1018 - val_accuracy: 0.5258\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1364 - accuracy: 0.4000 - val_loss: 1.0711 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2019 - accuracy: 0.4400 - val_loss: 1.0498 - val_accuracy: 0.4948\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1147 - accuracy: 0.5000 - val_loss: 1.0616 - val_accuracy: 0.4845\n",
      "Epoch 94\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.2067 - accuracy: 0.5400 - val_loss: 1.1177 - val_accuracy: 0.4900\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1132 - accuracy: 0.3800 - val_loss: 1.0896 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0036 - accuracy: 0.5510 - val_loss: 1.0660 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.0791 - accuracy: 0.5200 - val_loss: 1.0465 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1973 - accuracy: 0.4800 - val_loss: 1.0369 - val_accuracy: 0.5800\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1299 - accuracy: 0.4400 - val_loss: 1.0328 - val_accuracy: 0.5900\n",
      "Epoch 95\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1421 - accuracy: 0.4600 - val_loss: 1.0513 - val_accuracy: 0.5306\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0323 - accuracy: 0.5600 - val_loss: 1.0640 - val_accuracy: 0.5204\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.1455 - accuracy: 0.4000 - val_loss: 1.0915 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0153 - accuracy: 0.5800 - val_loss: 1.1370 - val_accuracy: 0.4490\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.0727 - accuracy: 0.5200 - val_loss: 1.1532 - val_accuracy: 0.4796\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.4839 - accuracy: 0.4000 - val_loss: 1.1298 - val_accuracy: 0.4592\n",
      "Epoch 96\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.0155 - accuracy: 0.5800 - val_loss: 1.0414 - val_accuracy: 0.5600\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.3132 - accuracy: 0.4000 - val_loss: 0.9808 - val_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0382 - accuracy: 0.5200 - val_loss: 0.9999 - val_accuracy: 0.5900\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1234 - accuracy: 0.5000 - val_loss: 1.0517 - val_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1893 - accuracy: 0.4800 - val_loss: 1.0733 - val_accuracy: 0.5300\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.9707 - accuracy: 0.5800 - val_loss: 1.0725 - val_accuracy: 0.5300\n",
      "Epoch 97\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1102 - accuracy: 0.5200 - val_loss: 1.2374 - val_accuracy: 0.3800\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.2118 - accuracy: 0.3800 - val_loss: 1.2233 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1964 - accuracy: 0.4600 - val_loss: 1.2130 - val_accuracy: 0.3900\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1407 - accuracy: 0.5200 - val_loss: 1.2193 - val_accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.2572 - accuracy: 0.4400 - val_loss: 1.2167 - val_accuracy: 0.3800\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1452 - accuracy: 0.4600 - val_loss: 1.2166 - val_accuracy: 0.4200\n",
      "Epoch 98\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0731 - accuracy: 0.5600 - val_loss: 1.0840 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0701 - accuracy: 0.5400 - val_loss: 1.0598 - val_accuracy: 0.4747\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1002 - accuracy: 0.6400 - val_loss: 1.0581 - val_accuracy: 0.5253\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.3993 - accuracy: 0.3800 - val_loss: 1.0628 - val_accuracy: 0.5354\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1500 - accuracy: 0.4600 - val_loss: 1.0696 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.0076 - accuracy: 0.5000 - val_loss: 1.0715 - val_accuracy: 0.5051\n",
      "Epoch 99\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1024 - accuracy: 0.5200 - val_loss: 1.2166 - val_accuracy: 0.4700\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0070 - accuracy: 0.5400 - val_loss: 1.2324 - val_accuracy: 0.4600\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.1031 - accuracy: 0.4800 - val_loss: 1.2475 - val_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1447 - accuracy: 0.4000 - val_loss: 1.2578 - val_accuracy: 0.4400\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.9493 - accuracy: 0.5800 - val_loss: 1.2792 - val_accuracy: 0.4300\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.2019 - accuracy: 0.4694 - val_loss: 1.2885 - val_accuracy: 0.4200\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_ds = train_dataset.shuffle(n_train).batch(batch_size)\n",
    "    val_ds = validation_dataset.shuffle(n_test).batch(n_test)\n",
    "    \n",
    "    x_val, y_val, length_val = next(iter(val_ds))\n",
    "    x_val, y_val = slice_accordingly(x_val, y_val)\n",
    "    \n",
    "    for features, labels, lengths in train_ds:\n",
    "        features, labels = slice_accordingly(features, labels)\n",
    "        \n",
    "        history = model.fit(features, labels,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=1) \n",
    "        predictions = model.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
