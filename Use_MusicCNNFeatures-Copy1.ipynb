{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8632ad-da86-4079-8e6f-d0a4b6c78133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90bcd99-d314-4ab0-b3e8-618304bdbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bccb7d2-3b34-4654-871f-97ea89b26a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "taggram = np.load(\"MusicCNNFeatures/taggram_array.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ac7b98-97ad-48ff-9fa5-a60167e3ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 20, 50)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(taggram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff18ee0-acc4-41b2-afb8-55d925925d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_songs = pd.read_csv(\"./preprocessing/labels.csv\")\n",
    "info_songs = pd.read_csv(\"./Info/info.csv\")\n",
    "\n",
    "select_label = \"genre\"\n",
    "\n",
    "if select_label == \"genre\":\n",
    "    labels = label_songs[select_label].map({\"classical\":0, \"electronic\":1, \"pop\":2, \"rock\":3})\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42dc4dac-3248-4e9e-8079-35394e3c9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(label_songs)\n",
    "idx = np.random.permutation(n_data)\n",
    "info_songs = info_songs.reindex(idx)\n",
    "taggram = taggram[idx, :, :]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1a6b5b-d0f1-4fe8-ba2b-894b9e52e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "sample_size = (5, 50)\n",
    "\n",
    "drop_out_rate = 0.2\n",
    "\n",
    "# very simple keras Sequential model\n",
    "input_tensor = Input(sample_size)\n",
    "x = layers.Dense(50, activation=\"relu\")(input_tensor)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961c4fd9-40e5-4ceb-bbd3-f37d706a7f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5, 50)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5, 50)             2550      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2780c88-f49f-4bb4-acdc-fa105a7aa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_accordingly(input_tensor, labels, size=5):\n",
    "\n",
    "    input_shape = (tf.shape(input_tensor).numpy())\n",
    "    \n",
    "    input_shape[1] = size\n",
    "    size = input_shape\n",
    "    \n",
    "    sliced_tensor = tf.image.random_crop(input_tensor, size)\n",
    "    \n",
    "    nan_values, idx = tf.unique(tf.gather(tf.where(tf.math.is_nan(sliced_tensor)), 0, axis=1))\n",
    "    nan_values = nan_values.numpy()\n",
    "  \n",
    "    msk = np.zeros((input_shape[0]), dtype=np.bool)\n",
    "    msk[nan_values] = True\n",
    "    msk = ~msk\n",
    "\n",
    "    sliced_tensor = tf.boolean_mask(sliced_tensor, msk , axis=0)\n",
    "    labels = tf.boolean_mask(labels , msk, axis=0)\n",
    "    \n",
    "    return sliced_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb10183-5a43-4ba8-97a2-c70cc07aa4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_validation = 0.5\n",
    "n_test = int(fraction_validation*len(labels))\n",
    "n_train = len(labels) - n_test\n",
    "\n",
    "train_features, train_labels = taggram[:n_train], labels[:n_train]\n",
    "validation_features, validation_labels = taggram[n_train:], labels[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f9a5bc-d8f3-404d-9ebf-783a83c31e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b534342e-bfd0-4218-ad1b-a71a0801739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "2/2 [==============================] - 1s 257ms/step - loss: 1.3875 - accuracy: 0.1915 - val_loss: 1.3943 - val_accuracy: 0.2081\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.4102 - accuracy: 0.2200 - val_loss: 1.3739 - val_accuracy: 0.2589\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3728 - accuracy: 0.3200 - val_loss: 1.3534 - val_accuracy: 0.3350\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.3326 - accuracy: 0.4200 - val_loss: 1.3335 - val_accuracy: 0.3858\n",
      "Epoch 1\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.3288 - accuracy: 0.3400 - val_loss: 1.3154 - val_accuracy: 0.5250\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.2817 - accuracy: 0.6327 - val_loss: 1.2964 - val_accuracy: 0.5850\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.2898 - accuracy: 0.5800 - val_loss: 1.2780 - val_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.2857 - accuracy: 0.4898 - val_loss: 1.2590 - val_accuracy: 0.6400\n",
      "Epoch 2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.2798 - accuracy: 0.5918 - val_loss: 1.2424 - val_accuracy: 0.6550\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.2047 - accuracy: 0.6939 - val_loss: 1.2232 - val_accuracy: 0.6800\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.2412 - accuracy: 0.5918 - val_loss: 1.2040 - val_accuracy: 0.6900\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1689 - accuracy: 0.8163 - val_loss: 1.1843 - val_accuracy: 0.6950\n",
      "Epoch 3\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1909 - accuracy: 0.6531 - val_loss: 1.1640 - val_accuracy: 0.7100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.1413 - accuracy: 0.7800 - val_loss: 1.1435 - val_accuracy: 0.7100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.1175 - accuracy: 0.7143 - val_loss: 1.1228 - val_accuracy: 0.7150\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.1609 - accuracy: 0.6200 - val_loss: 1.1025 - val_accuracy: 0.7150\n",
      "Epoch 4\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0631 - accuracy: 0.7400 - val_loss: 1.0748 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0443 - accuracy: 0.7800 - val_loss: 1.0534 - val_accuracy: 0.7350\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0304 - accuracy: 0.6939 - val_loss: 1.0310 - val_accuracy: 0.7350\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0545 - accuracy: 0.6875 - val_loss: 1.0086 - val_accuracy: 0.7350\n",
      "Epoch 5\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.9769 - accuracy: 0.8200 - val_loss: 0.9789 - val_accuracy: 0.7411\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.9573 - accuracy: 0.7600 - val_loss: 0.9559 - val_accuracy: 0.7411\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.9583 - accuracy: 0.7292 - val_loss: 0.9330 - val_accuracy: 0.7462\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.8867 - accuracy: 0.7600 - val_loss: 0.9107 - val_accuracy: 0.7462\n",
      "Epoch 6\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.9436 - accuracy: 0.6875 - val_loss: 0.8902 - val_accuracy: 0.7286\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.8359 - accuracy: 0.7959 - val_loss: 0.8682 - val_accuracy: 0.7286\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.9640 - accuracy: 0.6600 - val_loss: 0.8472 - val_accuracy: 0.7286\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.7936 - accuracy: 0.7200 - val_loss: 0.8269 - val_accuracy: 0.7286\n",
      "Epoch 7\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.8676 - accuracy: 0.7800 - val_loss: 0.8063 - val_accuracy: 0.7513\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.8082 - accuracy: 0.7200 - val_loss: 0.7875 - val_accuracy: 0.7513\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7681 - accuracy: 0.7347 - val_loss: 0.7698 - val_accuracy: 0.7513\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.7529 - accuracy: 0.7755 - val_loss: 0.7531 - val_accuracy: 0.7513\n",
      "Epoch 8\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7930 - accuracy: 0.7347 - val_loss: 0.7434 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7682 - accuracy: 0.7000 - val_loss: 0.7285 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.7296 - accuracy: 0.7800 - val_loss: 0.7142 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6863 - accuracy: 0.7800 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 9\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7940 - accuracy: 0.6800 - val_loss: 0.6849 - val_accuracy: 0.7588\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7255 - accuracy: 0.7400 - val_loss: 0.6740 - val_accuracy: 0.7588\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6342 - accuracy: 0.7551 - val_loss: 0.6638 - val_accuracy: 0.7638\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6524 - accuracy: 0.7347 - val_loss: 0.6539 - val_accuracy: 0.7688\n",
      "Epoch 10\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7014 - accuracy: 0.8000 - val_loss: 0.6448 - val_accuracy: 0.7614\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7005 - accuracy: 0.7800 - val_loss: 0.6360 - val_accuracy: 0.7563\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.7818 - accuracy: 0.6600 - val_loss: 0.6275 - val_accuracy: 0.7665\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5819 - accuracy: 0.7400 - val_loss: 0.6206 - val_accuracy: 0.7614\n",
      "Epoch 11\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5599 - accuracy: 0.8125 - val_loss: 0.6250 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.7395 - accuracy: 0.7200 - val_loss: 0.6201 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5193 - accuracy: 0.7959 - val_loss: 0.6149 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6191 - accuracy: 0.8000 - val_loss: 0.6088 - val_accuracy: 0.7500\n",
      "Epoch 12\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5780 - accuracy: 0.8000 - val_loss: 0.5946 - val_accuracy: 0.7487\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5776 - accuracy: 0.8200 - val_loss: 0.5888 - val_accuracy: 0.7638\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6373 - accuracy: 0.7292 - val_loss: 0.5830 - val_accuracy: 0.7638\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4938 - accuracy: 0.8163 - val_loss: 0.5780 - val_accuracy: 0.7688\n",
      "Epoch 13\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5321 - accuracy: 0.8200 - val_loss: 0.5709 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6051 - accuracy: 0.7200 - val_loss: 0.5665 - val_accuracy: 0.7839\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6261 - accuracy: 0.7800 - val_loss: 0.5635 - val_accuracy: 0.7688\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6347 - accuracy: 0.8367 - val_loss: 0.5610 - val_accuracy: 0.7688\n",
      "Epoch 14\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5799 - accuracy: 0.8200 - val_loss: 0.5601 - val_accuracy: 0.7688\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5462 - accuracy: 0.7347 - val_loss: 0.5565 - val_accuracy: 0.7839\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5676 - accuracy: 0.8400 - val_loss: 0.5539 - val_accuracy: 0.7839\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.5087 - accuracy: 0.8125 - val_loss: 0.5509 - val_accuracy: 0.7739\n",
      "Epoch 15\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5443 - accuracy: 0.8600 - val_loss: 0.6112 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6017 - accuracy: 0.7400 - val_loss: 0.6092 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7126 - accuracy: 0.6600 - val_loss: 0.6081 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5985 - accuracy: 0.7143 - val_loss: 0.6064 - val_accuracy: 0.7350\n",
      "Epoch 16\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7290 - accuracy: 0.6400 - val_loss: 0.6356 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4318 - accuracy: 0.8400 - val_loss: 0.6337 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6484 - accuracy: 0.7800 - val_loss: 0.6310 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5536 - accuracy: 0.8163 - val_loss: 0.6297 - val_accuracy: 0.7300\n",
      "Epoch 17\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.7071 - accuracy: 0.7200 - val_loss: 0.5384 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5662 - accuracy: 0.8200 - val_loss: 0.5386 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5105 - accuracy: 0.8000 - val_loss: 0.5368 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4535 - accuracy: 0.7872 - val_loss: 0.5342 - val_accuracy: 0.7940\n",
      "Epoch 18\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4710 - accuracy: 0.7800 - val_loss: 0.5298 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5098 - accuracy: 0.8000 - val_loss: 0.5274 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4222 - accuracy: 0.8800 - val_loss: 0.5274 - val_accuracy: 0.7839\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6441 - accuracy: 0.7000 - val_loss: 0.5266 - val_accuracy: 0.7889\n",
      "Epoch 19\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4456 - accuracy: 0.8571 - val_loss: 0.6036 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.8185 - accuracy: 0.6200 - val_loss: 0.6013 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4264 - accuracy: 0.8800 - val_loss: 0.5996 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5482 - accuracy: 0.7292 - val_loss: 0.5987 - val_accuracy: 0.7250\n",
      "Epoch 20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5216 - accuracy: 0.7600 - val_loss: 0.5260 - val_accuracy: 0.7739\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5149 - accuracy: 0.7347 - val_loss: 0.5254 - val_accuracy: 0.7638\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4841 - accuracy: 0.8571 - val_loss: 0.5240 - val_accuracy: 0.7789\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5381 - accuracy: 0.7755 - val_loss: 0.5228 - val_accuracy: 0.7789\n",
      "Epoch 21\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5607 - accuracy: 0.8400 - val_loss: 0.5936 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5284 - accuracy: 0.8200 - val_loss: 0.5937 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4265 - accuracy: 0.8776 - val_loss: 0.5930 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5004 - accuracy: 0.7959 - val_loss: 0.5925 - val_accuracy: 0.7350\n",
      "Epoch 22\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4468 - accuracy: 0.8600 - val_loss: 0.5171 - val_accuracy: 0.7614\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4976 - accuracy: 0.7800 - val_loss: 0.5165 - val_accuracy: 0.7665\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4808 - accuracy: 0.8400 - val_loss: 0.5150 - val_accuracy: 0.7665\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5077 - accuracy: 0.7551 - val_loss: 0.5119 - val_accuracy: 0.7716\n",
      "Epoch 23\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4291 - accuracy: 0.7917 - val_loss: 0.4996 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.7232 - accuracy: 0.6800 - val_loss: 0.4980 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5096 - accuracy: 0.7600 - val_loss: 0.4967 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5044 - accuracy: 0.8000 - val_loss: 0.4953 - val_accuracy: 0.8100\n",
      "Epoch 24\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5249 - accuracy: 0.8200 - val_loss: 0.4993 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.5799 - accuracy: 0.7200 - val_loss: 0.4987 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.3432 - accuracy: 0.8980 - val_loss: 0.4982 - val_accuracy: 0.7839\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4791 - accuracy: 0.7800 - val_loss: 0.4973 - val_accuracy: 0.7889\n",
      "Epoch 25\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4590 - accuracy: 0.7800 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5173 - accuracy: 0.8776 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5464 - accuracy: 0.8200 - val_loss: 0.5453 - val_accuracy: 0.7550\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.4230 - accuracy: 0.8125 - val_loss: 0.5453 - val_accuracy: 0.7550\n",
      "Epoch 26\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3684 - accuracy: 0.8776 - val_loss: 0.6032 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5586 - accuracy: 0.8367 - val_loss: 0.6026 - val_accuracy: 0.7350\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4478 - accuracy: 0.8200 - val_loss: 0.6020 - val_accuracy: 0.7350\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6577 - accuracy: 0.7400 - val_loss: 0.5996 - val_accuracy: 0.7350\n",
      "Epoch 27\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4699 - accuracy: 0.8542 - val_loss: 0.5103 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4440 - accuracy: 0.8367 - val_loss: 0.5095 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4554 - accuracy: 0.8600 - val_loss: 0.5095 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5107 - accuracy: 0.7551 - val_loss: 0.5096 - val_accuracy: 0.7700\n",
      "Epoch 28\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3497 - accuracy: 0.8600 - val_loss: 0.5010 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3901 - accuracy: 0.9000 - val_loss: 0.5000 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.4799 - accuracy: 0.7959 - val_loss: 0.4991 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.4537 - accuracy: 0.8542 - val_loss: 0.4982 - val_accuracy: 0.7889\n",
      "Epoch 29\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4495 - accuracy: 0.8200 - val_loss: 0.4949 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5078 - accuracy: 0.8000 - val_loss: 0.4948 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5700 - accuracy: 0.7400 - val_loss: 0.4947 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4250 - accuracy: 0.8542 - val_loss: 0.4949 - val_accuracy: 0.8090\n",
      "Epoch 30\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4964 - accuracy: 0.7800 - val_loss: 0.5176 - val_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4843 - accuracy: 0.8200 - val_loss: 0.5180 - val_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3988 - accuracy: 0.8600 - val_loss: 0.5181 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4276 - accuracy: 0.8367 - val_loss: 0.5186 - val_accuracy: 0.7600\n",
      "Epoch 31\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4740 - accuracy: 0.8367 - val_loss: 0.4960 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4823 - accuracy: 0.8600 - val_loss: 0.4978 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4886 - accuracy: 0.7755 - val_loss: 0.4990 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4344 - accuracy: 0.8367 - val_loss: 0.4983 - val_accuracy: 0.8040\n",
      "Epoch 32\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5564 - accuracy: 0.7551 - val_loss: 0.4971 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4319 - accuracy: 0.8800 - val_loss: 0.4964 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.4046 - accuracy: 0.7959 - val_loss: 0.4947 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3699 - accuracy: 0.8600 - val_loss: 0.4929 - val_accuracy: 0.8141\n",
      "Epoch 33\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5068 - accuracy: 0.8400 - val_loss: 0.6259 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2628 - accuracy: 0.9184 - val_loss: 0.6248 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5564 - accuracy: 0.7600 - val_loss: 0.6231 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5017 - accuracy: 0.8367 - val_loss: 0.6212 - val_accuracy: 0.7250\n",
      "Epoch 34\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4807 - accuracy: 0.8000 - val_loss: 0.6194 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.4515 - accuracy: 0.8125 - val_loss: 0.6188 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4502 - accuracy: 0.8200 - val_loss: 0.6189 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4253 - accuracy: 0.7959 - val_loss: 0.6194 - val_accuracy: 0.7250\n",
      "Epoch 35\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4022 - accuracy: 0.8776 - val_loss: 0.6215 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3756 - accuracy: 0.8000 - val_loss: 0.6241 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4306 - accuracy: 0.7917 - val_loss: 0.6277 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.5421 - accuracy: 0.7800 - val_loss: 0.6284 - val_accuracy: 0.7300\n",
      "Epoch 36\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5607 - accuracy: 0.7800 - val_loss: 0.4956 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.2964 - accuracy: 0.9200 - val_loss: 0.4943 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4784 - accuracy: 0.8200 - val_loss: 0.4935 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4380 - accuracy: 0.8200 - val_loss: 0.4929 - val_accuracy: 0.7600\n",
      "Epoch 37\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5784 - accuracy: 0.7400 - val_loss: 0.4771 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3892 - accuracy: 0.7917 - val_loss: 0.4780 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4899 - accuracy: 0.8200 - val_loss: 0.4804 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4682 - accuracy: 0.7800 - val_loss: 0.4828 - val_accuracy: 0.8150\n",
      "Epoch 38\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3569 - accuracy: 0.9200 - val_loss: 0.4998 - val_accuracy: 0.7950\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4139 - accuracy: 0.8163 - val_loss: 0.4998 - val_accuracy: 0.7900\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4773 - accuracy: 0.7755 - val_loss: 0.4992 - val_accuracy: 0.7850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4229 - accuracy: 0.8571 - val_loss: 0.4992 - val_accuracy: 0.7900\n",
      "Epoch 39\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4875 - accuracy: 0.8600 - val_loss: 0.6066 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4863 - accuracy: 0.7708 - val_loss: 0.6077 - val_accuracy: 0.7100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4342 - accuracy: 0.8600 - val_loss: 0.6086 - val_accuracy: 0.7100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4000 - accuracy: 0.8571 - val_loss: 0.6098 - val_accuracy: 0.7150\n",
      "Epoch 40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5110 - accuracy: 0.8400 - val_loss: 0.4963 - val_accuracy: 0.7850\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4471 - accuracy: 0.8542 - val_loss: 0.4963 - val_accuracy: 0.7800\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4474 - accuracy: 0.8400 - val_loss: 0.4955 - val_accuracy: 0.7800\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3816 - accuracy: 0.8367 - val_loss: 0.4946 - val_accuracy: 0.7800\n",
      "Epoch 41\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.4398 - accuracy: 0.8000 - val_loss: 0.4841 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3726 - accuracy: 0.8600 - val_loss: 0.4836 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3928 - accuracy: 0.7800 - val_loss: 0.4820 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5472 - accuracy: 0.7347 - val_loss: 0.4796 - val_accuracy: 0.8100\n",
      "Epoch 42\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3104 - accuracy: 0.8400 - val_loss: 0.4880 - val_accuracy: 0.7850\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6545 - accuracy: 0.7755 - val_loss: 0.4870 - val_accuracy: 0.7900\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4770 - accuracy: 0.7959 - val_loss: 0.4874 - val_accuracy: 0.7900\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4824 - accuracy: 0.8200 - val_loss: 0.4874 - val_accuracy: 0.7900\n",
      "Epoch 43\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3625 - accuracy: 0.8776 - val_loss: 0.4773 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4219 - accuracy: 0.8163 - val_loss: 0.4774 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4458 - accuracy: 0.8200 - val_loss: 0.4773 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5882 - accuracy: 0.8000 - val_loss: 0.4784 - val_accuracy: 0.8200\n",
      "Epoch 44\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3681 - accuracy: 0.8750 - val_loss: 0.4855 - val_accuracy: 0.8020\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3294 - accuracy: 0.8776 - val_loss: 0.4865 - val_accuracy: 0.7919\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5376 - accuracy: 0.7400 - val_loss: 0.4882 - val_accuracy: 0.7919\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - accuracy: 0.8776 - val_loss: 0.4891 - val_accuracy: 0.7919\n",
      "Epoch 45\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4426 - accuracy: 0.8400 - val_loss: 0.4895 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6851 - accuracy: 0.6800 - val_loss: 0.4917 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3411 - accuracy: 0.8776 - val_loss: 0.4951 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - accuracy: 0.8200 - val_loss: 0.4978 - val_accuracy: 0.7990\n",
      "Epoch 46\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4807 - accuracy: 0.8163 - val_loss: 0.6250 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3065 - accuracy: 0.8980 - val_loss: 0.6256 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3671 - accuracy: 0.8800 - val_loss: 0.6270 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4828 - accuracy: 0.7959 - val_loss: 0.6300 - val_accuracy: 0.7400\n",
      "Epoch 47\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.3499 - accuracy: 0.8800 - val_loss: 0.5772 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3142 - accuracy: 0.9200 - val_loss: 0.5793 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5991 - accuracy: 0.8333 - val_loss: 0.5823 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4627 - accuracy: 0.7800 - val_loss: 0.5840 - val_accuracy: 0.7400\n",
      "Epoch 48\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3078 - accuracy: 0.8542 - val_loss: 0.4857 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6385 - accuracy: 0.7400 - val_loss: 0.4847 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5153 - accuracy: 0.8000 - val_loss: 0.4850 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4890 - accuracy: 0.7959 - val_loss: 0.4862 - val_accuracy: 0.8090\n",
      "Epoch 49\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5428 - accuracy: 0.7800 - val_loss: 0.4847 - val_accuracy: 0.8241\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4185 - accuracy: 0.8400 - val_loss: 0.4876 - val_accuracy: 0.8241\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5177 - accuracy: 0.8200 - val_loss: 0.4897 - val_accuracy: 0.8291\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.90 - 0s 63ms/step - loss: 0.4343 - accuracy: 0.8600 - val_loss: 0.4922 - val_accuracy: 0.8191\n",
      "Epoch 50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6569 - accuracy: 0.7200 - val_loss: 0.5355 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3563 - accuracy: 0.8800 - val_loss: 0.5354 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3794 - accuracy: 0.8800 - val_loss: 0.5344 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4554 - accuracy: 0.8400 - val_loss: 0.5336 - val_accuracy: 0.7350\n",
      "Epoch 51\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5181 - accuracy: 0.7917 - val_loss: 0.4966 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3613 - accuracy: 0.8800 - val_loss: 0.4969 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3795 - accuracy: 0.8367 - val_loss: 0.4980 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4056 - accuracy: 0.8600 - val_loss: 0.4975 - val_accuracy: 0.8200\n",
      "Epoch 52\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4161 - accuracy: 0.8163 - val_loss: 0.5006 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4346 - accuracy: 0.8200 - val_loss: 0.4993 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3272 - accuracy: 0.8600 - val_loss: 0.4975 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4729 - accuracy: 0.7755 - val_loss: 0.4951 - val_accuracy: 0.8040\n",
      "Epoch 53\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3255 - accuracy: 0.9400 - val_loss: 0.4912 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4672 - accuracy: 0.8571 - val_loss: 0.4889 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4241 - accuracy: 0.8367 - val_loss: 0.4866 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3891 - accuracy: 0.8367 - val_loss: 0.4855 - val_accuracy: 0.8040\n",
      "Epoch 54\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3494 - accuracy: 0.8800 - val_loss: 0.4846 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4524 - accuracy: 0.8400 - val_loss: 0.4837 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3766 - accuracy: 0.8800 - val_loss: 0.4840 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3457 - accuracy: 0.8776 - val_loss: 0.4848 - val_accuracy: 0.8090\n",
      "Epoch 55\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5311 - accuracy: 0.7600 - val_loss: 0.4788 - val_accuracy: 0.8050\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3426 - accuracy: 0.8800 - val_loss: 0.4793 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4267 - accuracy: 0.8600 - val_loss: 0.4805 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3893 - accuracy: 0.8800 - val_loss: 0.4827 - val_accuracy: 0.8150\n",
      "Epoch 56\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5534 - accuracy: 0.7755 - val_loss: 0.5714 - val_accuracy: 0.7550\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2665 - accuracy: 0.9375 - val_loss: 0.5735 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3209 - accuracy: 0.8980 - val_loss: 0.5756 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3970 - accuracy: 0.8000 - val_loss: 0.5768 - val_accuracy: 0.7450\n",
      "Epoch 57\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3670 - accuracy: 0.8400 - val_loss: 0.4962 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3955 - accuracy: 0.8200 - val_loss: 0.4951 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5902 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4105 - accuracy: 0.8600 - val_loss: 0.4929 - val_accuracy: 0.8141\n",
      "Epoch 58\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4679 - accuracy: 0.8400 - val_loss: 0.4948 - val_accuracy: 0.7900\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5627 - accuracy: 0.7800 - val_loss: 0.4946 - val_accuracy: 0.7900\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4837 - accuracy: 0.8400 - val_loss: 0.4945 - val_accuracy: 0.7900\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.3433 - accuracy: 0.8800 - val_loss: 0.4953 - val_accuracy: 0.7900\n",
      "Epoch 59\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4589 - accuracy: 0.8200 - val_loss: 0.4954 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4175 - accuracy: 0.8367 - val_loss: 0.4949 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3368 - accuracy: 0.9000 - val_loss: 0.4924 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3507 - accuracy: 0.8125 - val_loss: 0.4905 - val_accuracy: 0.8090\n",
      "Epoch 60\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3329 - accuracy: 0.8333 - val_loss: 0.4917 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5725 - accuracy: 0.7200 - val_loss: 0.4909 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2690 - accuracy: 0.9200 - val_loss: 0.4895 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4488 - accuracy: 0.8400 - val_loss: 0.4892 - val_accuracy: 0.7889\n",
      "Epoch 61\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4695 - accuracy: 0.8367 - val_loss: 0.5320 - val_accuracy: 0.7700\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3765 - accuracy: 0.9000 - val_loss: 0.5326 - val_accuracy: 0.7700\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4725 - accuracy: 0.7600 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4133 - accuracy: 0.8367 - val_loss: 0.5317 - val_accuracy: 0.7400\n",
      "Epoch 62\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4545 - accuracy: 0.8600 - val_loss: 0.4982 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3560 - accuracy: 0.8571 - val_loss: 0.5019 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4052 - accuracy: 0.8200 - val_loss: 0.5025 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3565 - accuracy: 0.8776 - val_loss: 0.5028 - val_accuracy: 0.8040\n",
      "Epoch 63\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3413 - accuracy: 0.8600 - val_loss: 0.5016 - val_accuracy: 0.7700\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5089 - accuracy: 0.8542 - val_loss: 0.4998 - val_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3898 - accuracy: 0.9000 - val_loss: 0.5008 - val_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.5144 - accuracy: 0.7400 - val_loss: 0.5030 - val_accuracy: 0.7800\n",
      "Epoch 64\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4799 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4005 - accuracy: 0.8571 - val_loss: 0.5056 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2797 - accuracy: 0.9200 - val_loss: 0.5014 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4674 - accuracy: 0.8800 - val_loss: 0.4938 - val_accuracy: 0.8090\n",
      "Epoch 65\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3745 - accuracy: 0.8800 - val_loss: 0.5579 - val_accuracy: 0.7700\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5117 - accuracy: 0.8200 - val_loss: 0.5608 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3544 - accuracy: 0.8800 - val_loss: 0.5639 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4671 - accuracy: 0.8400 - val_loss: 0.5668 - val_accuracy: 0.7450\n",
      "Epoch 66\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4335 - accuracy: 0.8571 - val_loss: 0.4911 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3744 - accuracy: 0.8400 - val_loss: 0.4908 - val_accuracy: 0.8040\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3602 - accuracy: 0.8367 - val_loss: 0.4916 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4646 - accuracy: 0.7551 - val_loss: 0.4922 - val_accuracy: 0.7990\n",
      "Epoch 67\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4281 - accuracy: 0.8400 - val_loss: 0.4849 - val_accuracy: 0.8050\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3024 - accuracy: 0.9184 - val_loss: 0.4832 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5495 - accuracy: 0.7800 - val_loss: 0.4825 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3455 - accuracy: 0.8571 - val_loss: 0.4822 - val_accuracy: 0.8100\n",
      "Epoch 68\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2776 - accuracy: 0.8776 - val_loss: 0.4883 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5444 - accuracy: 0.8000 - val_loss: 0.4885 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4357 - accuracy: 0.8600 - val_loss: 0.4887 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3463 - accuracy: 0.8542 - val_loss: 0.4886 - val_accuracy: 0.7990\n",
      "Epoch 69\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4266 - accuracy: 0.8367 - val_loss: 0.4884 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4829 - accuracy: 0.8400 - val_loss: 0.4880 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2381 - accuracy: 0.9388 - val_loss: 0.4869 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4190 - accuracy: 0.8367 - val_loss: 0.4859 - val_accuracy: 0.7940\n",
      "Epoch 70\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4188 - accuracy: 0.7800 - val_loss: 0.5280 - val_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3715 - accuracy: 0.8980 - val_loss: 0.5323 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3395 - accuracy: 0.9000 - val_loss: 0.5340 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5251 - accuracy: 0.7755 - val_loss: 0.5331 - val_accuracy: 0.7600\n",
      "Epoch 71\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2737 - accuracy: 0.9000 - val_loss: 0.5919 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3147 - accuracy: 0.8571 - val_loss: 0.5893 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6010 - accuracy: 0.8000 - val_loss: 0.5874 - val_accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3534 - accuracy: 0.8800 - val_loss: 0.5849 - val_accuracy: 0.7400\n",
      "Epoch 72\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4583 - accuracy: 0.8163 - val_loss: 0.4855 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4094 - accuracy: 0.7959 - val_loss: 0.4868 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3186 - accuracy: 0.9388 - val_loss: 0.4883 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3268 - accuracy: 0.8600 - val_loss: 0.4886 - val_accuracy: 0.8040\n",
      "Epoch 73\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4452 - accuracy: 0.8571 - val_loss: 0.4822 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2914 - accuracy: 0.9200 - val_loss: 0.4838 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4040 - accuracy: 0.8200 - val_loss: 0.4852 - val_accuracy: 0.8050\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5060 - accuracy: 0.7959 - val_loss: 0.4869 - val_accuracy: 0.8100\n",
      "Epoch 74\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2977 - accuracy: 0.8800 - val_loss: 0.4935 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4385 - accuracy: 0.8200 - val_loss: 0.4968 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3998 - accuracy: 0.9184 - val_loss: 0.4976 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4490 - accuracy: 0.8000 - val_loss: 0.4985 - val_accuracy: 0.7940\n",
      "Epoch 75\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4167 - accuracy: 0.7959 - val_loss: 0.6290 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4033 - accuracy: 0.8600 - val_loss: 0.6293 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4399 - accuracy: 0.8400 - val_loss: 0.6288 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4135 - accuracy: 0.8000 - val_loss: 0.6289 - val_accuracy: 0.7350\n",
      "Epoch 76\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3344 - accuracy: 0.9000 - val_loss: 0.4882 - val_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3513 - accuracy: 0.8571 - val_loss: 0.4878 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3985 - accuracy: 0.8400 - val_loss: 0.4864 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4457 - accuracy: 0.8200 - val_loss: 0.4866 - val_accuracy: 0.8100\n",
      "Epoch 77\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6168 - accuracy: 0.7000 - val_loss: 0.4851 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3768 - accuracy: 0.8776 - val_loss: 0.4857 - val_accuracy: 0.8150\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4705 - accuracy: 0.8163 - val_loss: 0.4883 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3537 - accuracy: 0.8400 - val_loss: 0.4884 - val_accuracy: 0.8100\n",
      "Epoch 78\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5068 - accuracy: 0.7800 - val_loss: 0.5021 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3665 - accuracy: 0.8571 - val_loss: 0.5025 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3795 - accuracy: 0.8571 - val_loss: 0.5023 - val_accuracy: 0.8141\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4450 - accuracy: 0.8000 - val_loss: 0.5028 - val_accuracy: 0.8090\n",
      "Epoch 79\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2998 - accuracy: 0.9400 - val_loss: 0.5032 - val_accuracy: 0.8191\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3959 - accuracy: 0.8400 - val_loss: 0.5047 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5050 - accuracy: 0.7800 - val_loss: 0.5060 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4502 - accuracy: 0.8400 - val_loss: 0.5078 - val_accuracy: 0.7940\n",
      "Epoch 80\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3888 - accuracy: 0.8571 - val_loss: 0.4997 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4546 - accuracy: 0.8400 - val_loss: 0.5032 - val_accuracy: 0.8050\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3918 - accuracy: 0.8400 - val_loss: 0.5031 - val_accuracy: 0.8050\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3386 - accuracy: 0.8600 - val_loss: 0.5016 - val_accuracy: 0.8050\n",
      "Epoch 81\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3692 - accuracy: 0.8800 - val_loss: 0.4990 - val_accuracy: 0.8050\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3667 - accuracy: 0.8600 - val_loss: 0.4973 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3426 - accuracy: 0.8776 - val_loss: 0.4947 - val_accuracy: 0.8100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4183 - accuracy: 0.8125 - val_loss: 0.4925 - val_accuracy: 0.8000\n",
      "Epoch 82\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4688 - accuracy: 0.8000 - val_loss: 0.5050 - val_accuracy: 0.7800\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4209 - accuracy: 0.8600 - val_loss: 0.5051 - val_accuracy: 0.7850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3164 - accuracy: 0.8542 - val_loss: 0.5049 - val_accuracy: 0.7850\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4573 - accuracy: 0.8600 - val_loss: 0.5053 - val_accuracy: 0.7850\n",
      "Epoch 83\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3988 - accuracy: 0.8200 - val_loss: 0.4925 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2279 - accuracy: 0.9796 - val_loss: 0.4945 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3222 - accuracy: 0.8571 - val_loss: 0.4937 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5004 - accuracy: 0.8200 - val_loss: 0.4888 - val_accuracy: 0.8000\n",
      "Epoch 84\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3908 - accuracy: 0.8600 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.5366 - accuracy: 0.7400 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3483 - accuracy: 0.8800 - val_loss: 0.5282 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4733 - accuracy: 0.7959 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 85\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4138 - accuracy: 0.8571 - val_loss: 0.4933 - val_accuracy: 0.7850\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4323 - accuracy: 0.7800 - val_loss: 0.4930 - val_accuracy: 0.7800\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4864 - accuracy: 0.8200 - val_loss: 0.4934 - val_accuracy: 0.7700\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3721 - accuracy: 0.8571 - val_loss: 0.4934 - val_accuracy: 0.7600\n",
      "Epoch 86\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3471 - accuracy: 0.8800 - val_loss: 0.5593 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3707 - accuracy: 0.9200 - val_loss: 0.5599 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4655 - accuracy: 0.8400 - val_loss: 0.5619 - val_accuracy: 0.7600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3181 - accuracy: 0.8980 - val_loss: 0.5662 - val_accuracy: 0.7500\n",
      "Epoch 87\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4384 - accuracy: 0.8776 - val_loss: 0.4990 - val_accuracy: 0.7800\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3318 - accuracy: 0.8571 - val_loss: 0.5006 - val_accuracy: 0.7700\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3599 - accuracy: 0.8776 - val_loss: 0.5036 - val_accuracy: 0.7650\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3960 - accuracy: 0.8200 - val_loss: 0.5065 - val_accuracy: 0.7700\n",
      "Epoch 88\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4372 - accuracy: 0.8163 - val_loss: 0.4969 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4105 - accuracy: 0.8200 - val_loss: 0.4962 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3713 - accuracy: 0.8367 - val_loss: 0.4925 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3167 - accuracy: 0.8800 - val_loss: 0.4889 - val_accuracy: 0.7940\n",
      "Epoch 89\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3376 - accuracy: 0.8800 - val_loss: 0.5996 - val_accuracy: 0.7200\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3916 - accuracy: 0.8367 - val_loss: 0.5985 - val_accuracy: 0.7300\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5152 - accuracy: 0.7400 - val_loss: 0.5950 - val_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3000 - accuracy: 0.8800 - val_loss: 0.5916 - val_accuracy: 0.7300\n",
      "Epoch 90\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5465 - accuracy: 0.7800 - val_loss: 0.4759 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.2766 - accuracy: 0.9200 - val_loss: 0.4762 - val_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4292 - accuracy: 0.8333 - val_loss: 0.4766 - val_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3080 - accuracy: 0.8776 - val_loss: 0.4762 - val_accuracy: 0.8250\n",
      "Epoch 91\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4855 - accuracy: 0.8600 - val_loss: 0.4768 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5038 - accuracy: 0.8163 - val_loss: 0.4774 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3666 - accuracy: 0.8600 - val_loss: 0.4787 - val_accuracy: 0.8200\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3502 - accuracy: 0.9000 - val_loss: 0.4802 - val_accuracy: 0.8200\n",
      "Epoch 92\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4584 - accuracy: 0.7800 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3926 - accuracy: 0.8200 - val_loss: 0.5669 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2429 - accuracy: 0.9600 - val_loss: 0.5719 - val_accuracy: 0.7450\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3871 - accuracy: 0.7959 - val_loss: 0.5744 - val_accuracy: 0.7450\n",
      "Epoch 93\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3722 - accuracy: 0.8400 - val_loss: 0.4952 - val_accuracy: 0.7889\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5150 - accuracy: 0.8400 - val_loss: 0.4968 - val_accuracy: 0.7940\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3323 - accuracy: 0.9000 - val_loss: 0.4957 - val_accuracy: 0.8090\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3427 - accuracy: 0.8571 - val_loss: 0.4939 - val_accuracy: 0.8040\n",
      "Epoch 94\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3556 - accuracy: 0.9184 - val_loss: 0.4888 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3466 - accuracy: 0.8600 - val_loss: 0.4885 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3260 - accuracy: 0.8571 - val_loss: 0.4897 - val_accuracy: 0.7990\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5000 - accuracy: 0.7400 - val_loss: 0.4894 - val_accuracy: 0.8040\n",
      "Epoch 95\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2656 - accuracy: 0.9184 - val_loss: 0.4752 - val_accuracy: 0.8173\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4059 - accuracy: 0.8367 - val_loss: 0.4755 - val_accuracy: 0.8173\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3694 - accuracy: 0.8776 - val_loss: 0.4741 - val_accuracy: 0.8173\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5255 - accuracy: 0.7800 - val_loss: 0.4746 - val_accuracy: 0.8173\n",
      "Epoch 96\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4939 - accuracy: 0.8000 - val_loss: 0.4786 - val_accuracy: 0.8291\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2313 - accuracy: 0.9600 - val_loss: 0.4800 - val_accuracy: 0.8291\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4397 - accuracy: 0.7708 - val_loss: 0.4827 - val_accuracy: 0.8241\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4042 - accuracy: 0.8800 - val_loss: 0.4827 - val_accuracy: 0.8342\n",
      "Epoch 97\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3154 - accuracy: 0.9200 - val_loss: 0.4844 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-98c81803b8b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         history = model.fit(features, labels,\n\u001b[0;32m     22\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                            verbose=1) \n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sergi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1170\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[0;32m   1171\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sergi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sergi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mC:\\Users\\sergi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sergi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mC:\\Users\\sergi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3119\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 3120\u001b[1;33m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3122\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_1\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_ds = train_dataset.shuffle(n_train).batch(batch_size)\n",
    "    val_ds = validation_dataset.shuffle(n_test).batch(n_test)\n",
    "    \n",
    "    x_val, y_val = next(iter(val_ds))\n",
    "    x_val, y_val = slice_accordingly(x_val, y_val)\n",
    "    \n",
    "    for features, labels in train_ds:\n",
    "        features, labels = slice_accordingly(features, labels)\n",
    "        \n",
    "        history = model.fit(features, labels,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=1) \n",
    "        predictions = model.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
