{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8632ad-da86-4079-8e6f-d0a4b6c78133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90bcd99-d314-4ab0-b3e8-618304bdbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bccb7d2-3b34-4654-871f-97ea89b26a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool5 = np.load(\"MusicCNNFeatures/pool5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ac7b98-97ad-48ff-9fa5-a60167e3ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(pool5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff18ee0-acc4-41b2-afb8-55d925925d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_songs = pd.read_csv(\"./preprocessing/labels.csv\")\n",
    "info_songs = pd.read_csv(\"./Info/info.csv\")\n",
    "\n",
    "select_label = \"genre\"\n",
    "\n",
    "if select_label == \"genre\":\n",
    "    labels = label_songs[select_label].map({\"classical\":0, \"electronic\":1, \"pop\":2, \"rock\":3})\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42dc4dac-3248-4e9e-8079-35394e3c9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(label_songs)\n",
    "idx = np.random.permutation(n_data)\n",
    "info_songs = info_songs.reindex(idx)\n",
    "pool5 = pool5[idx, :, :]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1a6b5b-d0f1-4fe8-ba2b-894b9e52e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "sample_size = (10, 128, 1)\n",
    "\n",
    "drop_out_rate = 0.5\n",
    "\n",
    "# very simple keras Sequential model\n",
    "input_tensor = Input(sample_size)\n",
    "x = layers.Conv2D(5, (10, 1), padding=\"valid\", activation=\"relu\", strides=1)(input_tensor)\n",
    "#x = layers.MaxPooling2D(pool_size=(4,1))(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961c4fd9-40e5-4ceb-bbd3-f37d706a7f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 128, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1, 128, 5)         55        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 128, 5)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 128, 20)        120       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 10244     \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2780c88-f49f-4bb4-acdc-fa105a7aa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_accordingly(input_tensor, labels, size=10):\n",
    "\n",
    "    input_shape = (tf.shape(input_tensor).numpy())\n",
    "    \n",
    "    input_shape[1] = size\n",
    "    size = input_shape\n",
    "    \n",
    "    sliced_tensor = tf.image.random_crop(input_tensor, size)\n",
    "    \n",
    "    nan_values, idx = tf.unique(tf.gather(tf.where(tf.math.is_nan(sliced_tensor)), 0, axis=1))\n",
    "    nan_values = nan_values.numpy()\n",
    "  \n",
    "    msk = np.zeros((input_shape[0]), dtype=np.bool)\n",
    "    msk[nan_values] = True\n",
    "    msk = ~msk\n",
    "\n",
    "    sliced_tensor = tf.boolean_mask(sliced_tensor, msk , axis=0)\n",
    "    labels = tf.boolean_mask(labels , msk, axis=0)\n",
    "    \n",
    "    return sliced_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb10183-5a43-4ba8-97a2-c70cc07aa4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "fraction_validation = 0.25\n",
    "n_test = int(fraction_validation*len(labels))\n",
    "n_train = len(labels) - n_test\n",
    "\n",
    "train_features, train_labels = pool5[:n_train], labels[:n_train]\n",
    "validation_features, validation_labels = pool5[n_train:], labels[n_train:]\n",
    "\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f9a5bc-d8f3-404d-9ebf-783a83c31e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b534342e-bfd0-4218-ad1b-a71a0801739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3527 - accuracy: 0.3000 - val_loss: 1.3967 - val_accuracy: 0.1856\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4138 - accuracy: 0.1500 - val_loss: 1.3858 - val_accuracy: 0.2577\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3840 - accuracy: 0.2500 - val_loss: 1.3708 - val_accuracy: 0.3093\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3192 - accuracy: 0.4500 - val_loss: 1.3560 - val_accuracy: 0.3608\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2935 - accuracy: 0.4500 - val_loss: 1.3409 - val_accuracy: 0.3505\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3952 - accuracy: 0.2500 - val_loss: 1.3266 - val_accuracy: 0.3814\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3923 - accuracy: 0.2105 - val_loss: 1.3130 - val_accuracy: 0.4227\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3404 - accuracy: 0.4000 - val_loss: 1.2995 - val_accuracy: 0.4639\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2865 - accuracy: 0.5000 - val_loss: 1.2861 - val_accuracy: 0.5052\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3981 - accuracy: 0.2500 - val_loss: 1.2727 - val_accuracy: 0.5464\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3618 - accuracy: 0.2500 - val_loss: 1.2591 - val_accuracy: 0.5567\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2278 - accuracy: 0.5000 - val_loss: 1.2449 - val_accuracy: 0.5567\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2564 - accuracy: 0.6500 - val_loss: 1.2303 - val_accuracy: 0.5464\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2562 - accuracy: 0.5500 - val_loss: 1.2154 - val_accuracy: 0.5464\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2536 - accuracy: 0.6500 - val_loss: 1.1996 - val_accuracy: 0.5670\n",
      "Epoch 1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1204 - accuracy: 0.7000 - val_loss: 1.1861 - val_accuracy: 0.5918\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1182 - accuracy: 0.7000 - val_loss: 1.1699 - val_accuracy: 0.5918\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2145 - accuracy: 0.4000 - val_loss: 1.1530 - val_accuracy: 0.5816\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2514 - accuracy: 0.4737 - val_loss: 1.1357 - val_accuracy: 0.5714\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.1358 - accuracy: 0.6000 - val_loss: 1.1178 - val_accuracy: 0.5816\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1605 - accuracy: 0.6500 - val_loss: 1.0991 - val_accuracy: 0.6020\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1023 - accuracy: 0.5500 - val_loss: 1.0802 - val_accuracy: 0.6020\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1370 - accuracy: 0.4500 - val_loss: 1.0598 - val_accuracy: 0.6020\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0165 - accuracy: 0.5500 - val_loss: 1.0382 - val_accuracy: 0.6122\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0093 - accuracy: 0.7000 - val_loss: 1.0156 - val_accuracy: 0.6429\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9890 - accuracy: 0.7500 - val_loss: 0.9919 - val_accuracy: 0.6429\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7924 - accuracy: 0.9000 - val_loss: 0.9689 - val_accuracy: 0.6633\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9384 - accuracy: 0.5500 - val_loss: 0.9477 - val_accuracy: 0.6531\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2155 - accuracy: 0.5500 - val_loss: 0.9281 - val_accuracy: 0.6429\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9642 - accuracy: 0.7000 - val_loss: 0.9079 - val_accuracy: 0.6429\n",
      "Epoch 2\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8187 - accuracy: 0.7000 - val_loss: 0.9243 - val_accuracy: 0.5900\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9343 - accuracy: 0.4500 - val_loss: 0.9049 - val_accuracy: 0.5900\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7355 - accuracy: 0.7500 - val_loss: 0.8857 - val_accuracy: 0.5900\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8684 - accuracy: 0.6500 - val_loss: 0.8663 - val_accuracy: 0.6300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6918 - accuracy: 0.7500 - val_loss: 0.8460 - val_accuracy: 0.6500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7654 - accuracy: 0.7000 - val_loss: 0.8271 - val_accuracy: 0.6700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8035 - accuracy: 0.7000 - val_loss: 0.8109 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6806 - accuracy: 0.8000 - val_loss: 0.7948 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9006 - accuracy: 0.6000 - val_loss: 0.7805 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5967 - accuracy: 0.8000 - val_loss: 0.7683 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8632 - accuracy: 0.6500 - val_loss: 0.7553 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7343 - accuracy: 0.7500 - val_loss: 0.7425 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6051 - accuracy: 0.9000 - val_loss: 0.7318 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9849 - accuracy: 0.5000 - val_loss: 0.7209 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8356 - accuracy: 0.5000 - val_loss: 0.7118 - val_accuracy: 0.6800\n",
      "Epoch 3\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4973 - accuracy: 0.7500 - val_loss: 0.6677 - val_accuracy: 0.7143\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5208 - accuracy: 0.7895 - val_loss: 0.6605 - val_accuracy: 0.7143\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9746 - accuracy: 0.4500 - val_loss: 0.6521 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5870 - accuracy: 0.7500 - val_loss: 0.6461 - val_accuracy: 0.7041\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5209 - accuracy: 0.8000 - val_loss: 0.6406 - val_accuracy: 0.6939\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6256 - accuracy: 0.6316 - val_loss: 0.6360 - val_accuracy: 0.6939\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7502 - accuracy: 0.6500 - val_loss: 0.6308 - val_accuracy: 0.7041\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3868 - accuracy: 0.9000 - val_loss: 0.6256 - val_accuracy: 0.7143\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7372 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.7143\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6287 - accuracy: 0.7000 - val_loss: 0.6155 - val_accuracy: 0.7143\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4410 - accuracy: 0.8000 - val_loss: 0.6112 - val_accuracy: 0.7143\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5065 - accuracy: 0.8000 - val_loss: 0.6056 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4309 - accuracy: 0.8500 - val_loss: 0.6018 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6329 - accuracy: 0.7000 - val_loss: 0.5985 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5334 - accuracy: 0.8000 - val_loss: 0.5939 - val_accuracy: 0.7347\n",
      "Epoch 4\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4363 - accuracy: 0.8000 - val_loss: 0.5449 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5603 - accuracy: 0.7000 - val_loss: 0.5342 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5296 - accuracy: 0.7500 - val_loss: 0.5236 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9717 - accuracy: 0.5500 - val_loss: 0.5145 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8674 - accuracy: 0.5500 - val_loss: 0.5083 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6946 - accuracy: 0.6842 - val_loss: 0.5023 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2710 - accuracy: 0.9000 - val_loss: 0.4975 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4158 - accuracy: 0.8000 - val_loss: 0.4929 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6930 - accuracy: 0.8000 - val_loss: 0.4902 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4895 - accuracy: 0.8000 - val_loss: 0.4881 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7526 - accuracy: 0.6000 - val_loss: 0.4873 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4489 - accuracy: 0.8000 - val_loss: 0.4872 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5761 - accuracy: 0.7368 - val_loss: 0.4905 - val_accuracy: 0.8265\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7058 - accuracy: 0.7500 - val_loss: 0.4980 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6682 - accuracy: 0.7500 - val_loss: 0.5071 - val_accuracy: 0.7755\n",
      "Epoch 5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6836 - accuracy: 0.6500 - val_loss: 0.5106 - val_accuracy: 0.6869\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3834 - accuracy: 0.8500 - val_loss: 0.5168 - val_accuracy: 0.6768\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4504 - accuracy: 0.8000 - val_loss: 0.5258 - val_accuracy: 0.6566\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4514 - accuracy: 0.7895 - val_loss: 0.5359 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3361 - accuracy: 0.8000 - val_loss: 0.5461 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9102 - accuracy: 0.7500 - val_loss: 0.5542 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6870 - accuracy: 0.6500 - val_loss: 0.5583 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5693 - accuracy: 0.7000 - val_loss: 0.5587 - val_accuracy: 0.6768\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4846 - accuracy: 0.8500 - val_loss: 0.5576 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6440 - accuracy: 0.7000 - val_loss: 0.5523 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7040 - accuracy: 0.7500 - val_loss: 0.5435 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7992 - accuracy: 0.7000 - val_loss: 0.5331 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5349 - accuracy: 0.8000 - val_loss: 0.5244 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4390 - accuracy: 0.7000 - val_loss: 0.5153 - val_accuracy: 0.6768\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 0.5012 - val_accuracy: 0.7071\n",
      "Epoch 6\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - accuracy: 0.7500 - val_loss: 0.5869 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5730 - accuracy: 0.6000 - val_loss: 0.5774 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6431 - accuracy: 0.6000 - val_loss: 0.5725 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4158 - accuracy: 0.8500 - val_loss: 0.5675 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8457 - accuracy: 0.6500 - val_loss: 0.5630 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3917 - accuracy: 0.8500 - val_loss: 0.5581 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4325 - accuracy: 0.7895 - val_loss: 0.5557 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6204 - accuracy: 0.6000 - val_loss: 0.5537 - val_accuracy: 0.7300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7717 - accuracy: 0.6000 - val_loss: 0.5525 - val_accuracy: 0.7300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6461 - accuracy: 0.7500 - val_loss: 0.5508 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4800 - accuracy: 0.7000 - val_loss: 0.5513 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4866 - accuracy: 0.8500 - val_loss: 0.5514 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2437 - accuracy: 0.8500 - val_loss: 0.5512 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6260 - accuracy: 0.8000 - val_loss: 0.5517 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4927 - accuracy: 0.9000 - val_loss: 0.5522 - val_accuracy: 0.7100\n",
      "Epoch 7\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.90 - 0s 63ms/step - loss: 0.3149 - accuracy: 0.9000 - val_loss: 0.4995 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3901 - accuracy: 0.8500 - val_loss: 0.5003 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8865 - accuracy: 0.6500 - val_loss: 0.5012 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4897 - accuracy: 0.7500 - val_loss: 0.5021 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3670 - accuracy: 0.8947 - val_loss: 0.5018 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7024 - accuracy: 0.6500 - val_loss: 0.5031 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3228 - accuracy: 0.8500 - val_loss: 0.5047 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3571 - accuracy: 0.8500 - val_loss: 0.5062 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4992 - accuracy: 0.8000 - val_loss: 0.5074 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5716 - accuracy: 0.7368 - val_loss: 0.5086 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4675 - accuracy: 0.8000 - val_loss: 0.5107 - val_accuracy: 0.8163\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - accuracy: 0.8500 - val_loss: 0.5147 - val_accuracy: 0.8163\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5893 - accuracy: 0.7000 - val_loss: 0.5231 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3517 - accuracy: 0.9000 - val_loss: 0.5304 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4711 - accuracy: 0.7000 - val_loss: 0.5380 - val_accuracy: 0.7041\n",
      "Epoch 8\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4957 - accuracy: 0.8500 - val_loss: 0.5411 - val_accuracy: 0.6939\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2426 - accuracy: 0.9500 - val_loss: 0.5433 - val_accuracy: 0.6939\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4478 - accuracy: 0.8500 - val_loss: 0.5440 - val_accuracy: 0.6939\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6561 - accuracy: 0.7500 - val_loss: 0.5414 - val_accuracy: 0.6939\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2449 - accuracy: 0.9500 - val_loss: 0.5377 - val_accuracy: 0.7041\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4356 - accuracy: 0.8000 - val_loss: 0.5284 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3211 - accuracy: 0.9000 - val_loss: 0.5216 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6626 - accuracy: 0.7500 - val_loss: 0.5189 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5243 - accuracy: 0.7500 - val_loss: 0.5169 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6150 - accuracy: 0.8000 - val_loss: 0.5145 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5815 - accuracy: 0.7500 - val_loss: 0.5161 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6374 - accuracy: 0.6500 - val_loss: 0.5126 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6111 - accuracy: 0.7500 - val_loss: 0.5107 - val_accuracy: 0.8163\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3255 - accuracy: 0.8500 - val_loss: 0.5070 - val_accuracy: 0.8265\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6613 - accuracy: 0.7500 - val_loss: 0.5076 - val_accuracy: 0.8163\n",
      "Epoch 9\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3412 - accuracy: 0.8500 - val_loss: 0.4829 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2801 - accuracy: 0.9500 - val_loss: 0.4816 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4553 - accuracy: 0.8000 - val_loss: 0.4776 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5334 - accuracy: 0.8333 - val_loss: 0.4748 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5825 - accuracy: 0.7000 - val_loss: 0.4743 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2876 - accuracy: 0.8000 - val_loss: 0.4732 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4295 - accuracy: 0.8500 - val_loss: 0.4734 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6053 - accuracy: 0.7500 - val_loss: 0.4752 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4735 - accuracy: 0.8500 - val_loss: 0.4758 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5103 - accuracy: 0.8000 - val_loss: 0.4778 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5407 - accuracy: 0.8000 - val_loss: 0.4821 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7461 - accuracy: 0.6500 - val_loss: 0.4865 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2463 - accuracy: 0.9000 - val_loss: 0.4895 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6893 - accuracy: 0.7000 - val_loss: 0.4898 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4786 - accuracy: 0.8500 - val_loss: 0.4877 - val_accuracy: 0.7551\n",
      "Epoch 10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9952 - accuracy: 0.6500 - val_loss: 0.4954 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1432 - accuracy: 0.9500 - val_loss: 0.4947 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4476 - accuracy: 0.7500 - val_loss: 0.4899 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4728 - accuracy: 0.8000 - val_loss: 0.4846 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2891 - accuracy: 0.8947 - val_loss: 0.4815 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7742 - accuracy: 0.6500 - val_loss: 0.4802 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4718 - accuracy: 0.8500 - val_loss: 0.4811 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3558 - accuracy: 0.9500 - val_loss: 0.4813 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4171 - accuracy: 0.8500 - val_loss: 0.4820 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3642 - accuracy: 0.8500 - val_loss: 0.4870 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5955 - accuracy: 0.6316 - val_loss: 0.4935 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6515 - accuracy: 0.7000 - val_loss: 0.4947 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3913 - accuracy: 0.9000 - val_loss: 0.4993 - val_accuracy: 0.7374\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4371 - accuracy: 0.8500 - val_loss: 0.4976 - val_accuracy: 0.7576\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8676 - accuracy: 0.6000 - val_loss: 0.4920 - val_accuracy: 0.7576\n",
      "Epoch 11\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2625 - accuracy: 0.9000 - val_loss: 0.4873 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4309 - accuracy: 0.7500 - val_loss: 0.4818 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3220 - accuracy: 0.8000 - val_loss: 0.4776 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6499 - accuracy: 0.6500 - val_loss: 0.4747 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8687 - accuracy: 0.6500 - val_loss: 0.4742 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3574 - accuracy: 0.8000 - val_loss: 0.4759 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5981 - accuracy: 0.7000 - val_loss: 0.4790 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2435 - accuracy: 0.9500 - val_loss: 0.4809 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6035 - accuracy: 0.7000 - val_loss: 0.4839 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6206 - accuracy: 0.6500 - val_loss: 0.4863 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5769 - accuracy: 0.7368 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6015 - accuracy: 0.8000 - val_loss: 0.4856 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6860 - accuracy: 0.7500 - val_loss: 0.4848 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3094 - accuracy: 0.9000 - val_loss: 0.4831 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5044 - accuracy: 0.8500 - val_loss: 0.4798 - val_accuracy: 0.7857\n",
      "Epoch 12\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4334 - accuracy: 0.8000 - val_loss: 0.4960 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3894 - accuracy: 0.7500 - val_loss: 0.4938 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4823 - accuracy: 0.8000 - val_loss: 0.4918 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3236 - accuracy: 0.9000 - val_loss: 0.4887 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4080 - accuracy: 0.8421 - val_loss: 0.4868 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6769 - accuracy: 0.6500 - val_loss: 0.4872 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4990 - accuracy: 0.8000 - val_loss: 0.4893 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4743 - accuracy: 0.8500 - val_loss: 0.4920 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2798 - accuracy: 0.8500 - val_loss: 0.4950 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5099 - accuracy: 0.8500 - val_loss: 0.4996 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5871 - accuracy: 0.8000 - val_loss: 0.5063 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3834 - accuracy: 0.8500 - val_loss: 0.5105 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4139 - accuracy: 0.8500 - val_loss: 0.5156 - val_accuracy: 0.7449\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4504 - accuracy: 0.7895 - val_loss: 0.5222 - val_accuracy: 0.7449\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3922 - accuracy: 0.8000 - val_loss: 0.5276 - val_accuracy: 0.7551\n",
      "Epoch 13\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4629 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4606 - accuracy: 0.7500 - val_loss: 0.5375 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3558 - accuracy: 0.8421 - val_loss: 0.5434 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6615 - accuracy: 0.7000 - val_loss: 0.5513 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6052 - accuracy: 0.7000 - val_loss: 0.5550 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5131 - accuracy: 0.8500 - val_loss: 0.5545 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4033 - accuracy: 0.9000 - val_loss: 0.5560 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2495 - accuracy: 0.9000 - val_loss: 0.5536 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4791 - accuracy: 0.7500 - val_loss: 0.5500 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5897 - accuracy: 0.7500 - val_loss: 0.5452 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5689 - accuracy: 0.8000 - val_loss: 0.5388 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3934 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3444 - accuracy: 0.9000 - val_loss: 0.5243 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3026 - accuracy: 0.8500 - val_loss: 0.5184 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5428 - accuracy: 0.7500 - val_loss: 0.5141 - val_accuracy: 0.7959\n",
      "Epoch 14\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3876 - accuracy: 0.8000 - val_loss: 0.4661 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3879 - accuracy: 0.8500 - val_loss: 0.4629 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3424 - accuracy: 0.8000 - val_loss: 0.4609 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5524 - accuracy: 0.8500 - val_loss: 0.4591 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6074 - accuracy: 0.6500 - val_loss: 0.4600 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4582 - accuracy: 0.8000 - val_loss: 0.4595 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7712 - accuracy: 0.5500 - val_loss: 0.4605 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6226 - accuracy: 0.8500 - val_loss: 0.4602 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3838 - accuracy: 0.8947 - val_loss: 0.4611 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3958 - accuracy: 0.9000 - val_loss: 0.4620 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2891 - accuracy: 0.9000 - val_loss: 0.4612 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4974 - accuracy: 0.7000 - val_loss: 0.4613 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4173 - accuracy: 0.8500 - val_loss: 0.4632 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3203 - accuracy: 0.9000 - val_loss: 0.4664 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3453 - accuracy: 0.8000 - val_loss: 0.4689 - val_accuracy: 0.7959\n",
      "Epoch 15\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2224 - accuracy: 0.9000 - val_loss: 0.5140 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2648 - accuracy: 0.9000 - val_loss: 0.5186 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4346 - accuracy: 0.8500 - val_loss: 0.5247 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4813 - accuracy: 0.7500 - val_loss: 0.5280 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6786 - accuracy: 0.6500 - val_loss: 0.5294 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3288 - accuracy: 0.8500 - val_loss: 0.5308 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4104 - accuracy: 0.8421 - val_loss: 0.5333 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3245 - accuracy: 0.9500 - val_loss: 0.5344 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6744 - accuracy: 0.7000 - val_loss: 0.5341 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5023 - accuracy: 0.8000 - val_loss: 0.5338 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6200 - accuracy: 0.6000 - val_loss: 0.5313 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3438 - accuracy: 0.8500 - val_loss: 0.5295 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3947 - accuracy: 0.8000 - val_loss: 0.5281 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5590 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7468 - accuracy: 0.7000 - val_loss: 0.5249 - val_accuracy: 0.7100\n",
      "Epoch 16\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4735 - accuracy: 0.8000 - val_loss: 0.5442 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3215 - accuracy: 0.9000 - val_loss: 0.5431 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2728 - accuracy: 0.8500 - val_loss: 0.5428 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5168 - accuracy: 0.7500 - val_loss: 0.5420 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6201 - accuracy: 0.7500 - val_loss: 0.5396 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3373 - accuracy: 0.8500 - val_loss: 0.5376 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7047 - accuracy: 0.6000 - val_loss: 0.5298 - val_accuracy: 0.7100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4924 - accuracy: 0.8500 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7787 - accuracy: 0.7000 - val_loss: 0.5189 - val_accuracy: 0.7600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5337 - accuracy: 0.8000 - val_loss: 0.5178 - val_accuracy: 0.7600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2444 - accuracy: 0.9000 - val_loss: 0.5174 - val_accuracy: 0.7600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3983 - accuracy: 0.8000 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8714 - accuracy: 0.6500 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3420 - accuracy: 0.8333 - val_loss: 0.5263 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2590 - accuracy: 0.9500 - val_loss: 0.5298 - val_accuracy: 0.6900\n",
      "Epoch 17\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6478 - accuracy: 0.7000 - val_loss: 0.4733 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3162 - accuracy: 0.9000 - val_loss: 0.4748 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3939 - accuracy: 0.8421 - val_loss: 0.4782 - val_accuracy: 0.7347\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4161 - accuracy: 0.8000 - val_loss: 0.4758 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3217 - accuracy: 0.9000 - val_loss: 0.4727 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6915 - accuracy: 0.7500 - val_loss: 0.4712 - val_accuracy: 0.7653\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4284 - accuracy: 0.9000 - val_loss: 0.4690 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4312 - accuracy: 0.7000 - val_loss: 0.4663 - val_accuracy: 0.8061\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4165 - accuracy: 0.7500 - val_loss: 0.4661 - val_accuracy: 0.8163\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3505 - accuracy: 0.8000 - val_loss: 0.4685 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3396 - accuracy: 0.8500 - val_loss: 0.4717 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2731 - accuracy: 0.8947 - val_loss: 0.4743 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3676 - accuracy: 0.8000 - val_loss: 0.4782 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5902 - accuracy: 0.7500 - val_loss: 0.4794 - val_accuracy: 0.7245\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4236 - accuracy: 0.8500 - val_loss: 0.4797 - val_accuracy: 0.7245\n",
      "Epoch 18\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2696 - accuracy: 0.9500 - val_loss: 0.5283 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3500 - accuracy: 0.8000 - val_loss: 0.5278 - val_accuracy: 0.7959\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7983 - accuracy: 0.6000 - val_loss: 0.5247 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5650 - accuracy: 0.8000 - val_loss: 0.5225 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3158 - accuracy: 0.9500 - val_loss: 0.5222 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3905 - accuracy: 0.7500 - val_loss: 0.5245 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5674 - accuracy: 0.8500 - val_loss: 0.5300 - val_accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1456 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6150 - accuracy: 0.5500 - val_loss: 0.5437 - val_accuracy: 0.7755\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4481 - accuracy: 0.7000 - val_loss: 0.5511 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5173 - accuracy: 0.7000 - val_loss: 0.5541 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3006 - accuracy: 0.9000 - val_loss: 0.5598 - val_accuracy: 0.7449\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6379 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4664 - accuracy: 0.8947 - val_loss: 0.5653 - val_accuracy: 0.7551\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7951 - accuracy: 0.6316 - val_loss: 0.5601 - val_accuracy: 0.7449\n",
      "Epoch 19\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2005 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4898 - accuracy: 0.6500 - val_loss: 0.5622 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3776 - accuracy: 0.8500 - val_loss: 0.5630 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4298 - accuracy: 0.8500 - val_loss: 0.5607 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1755 - accuracy: 0.9474 - val_loss: 0.5589 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8036 - accuracy: 0.6500 - val_loss: 0.5598 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2199 - accuracy: 0.9474 - val_loss: 0.5616 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6186 - accuracy: 0.5500 - val_loss: 0.5629 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4478 - accuracy: 0.7000 - val_loss: 0.5645 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6550 - accuracy: 0.8000 - val_loss: 0.5633 - val_accuracy: 0.6800\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6246 - accuracy: 0.8000 - val_loss: 0.5585 - val_accuracy: 0.6700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3972 - accuracy: 0.8000 - val_loss: 0.5509 - val_accuracy: 0.6600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2869 - accuracy: 0.8000 - val_loss: 0.5435 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4147 - accuracy: 0.7500 - val_loss: 0.5392 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2991 - accuracy: 0.9500 - val_loss: 0.5340 - val_accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "model = model_1\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_ds = train_dataset.shuffle(n_train).batch(batch_size)\n",
    "    val_ds = validation_dataset.shuffle(n_test).batch(n_test)\n",
    "    \n",
    "    x_val, y_val = next(iter(val_ds))\n",
    "    x_val, y_val = slice_accordingly(x_val, y_val)\n",
    "    \n",
    "    for X, Y in train_ds:\n",
    "        X, Y = slice_accordingly(X, Y)\n",
    "        \n",
    "        history = model.fit(X, Y,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "108eb558-157b-4275-b087-f1cce94f6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice(input_tensor, labels, begin, size=10):\n",
    "\n",
    "    input_shape = (tf.shape(input_tensor).numpy())\n",
    "    \n",
    "    begin = [0, begin, 0]\n",
    "    size = [100, size, 128]\n",
    "    \n",
    "    sliced_tensor = tf.slice(input_tensor, begin, size)\n",
    "    \n",
    "    nan_values, idx = tf.unique(tf.gather(tf.where(tf.math.is_nan(sliced_tensor)), 0, axis=1))\n",
    "    nan_values = nan_values.numpy()\n",
    "  \n",
    "    msk = np.zeros((input_shape[0]), dtype=np.bool)\n",
    "    msk[nan_values] = True\n",
    "    msk = ~msk\n",
    "\n",
    "    sliced_tensor = tf.boolean_mask(sliced_tensor, msk , axis=0)\n",
    "    labels = tf.boolean_mask(labels , msk, axis=0)\n",
    "    \n",
    "    return sliced_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5b48acf-f8d7-4d25-9254-e2a56744fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8a18f4ba8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_ds = validation_dataset.batch(n_test)\n",
    "\n",
    "x_val, y_val = next(iter(val_ds))\n",
    "x_val, y_val = slice(x_val, y_val, 0)\n",
    "\n",
    "predictions = model.predict(x_val)\n",
    "predictions = tf.argmax(predictions,1)\n",
    "\n",
    "cm = tf.math.confusion_matrix(\n",
    "    y_val, predictions, num_classes=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
