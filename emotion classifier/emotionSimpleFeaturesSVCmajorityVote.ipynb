{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73946ffd",
   "metadata": {},
   "source": [
    "## Majority Vote Support Vector Classifier for emotion, based on 4 simple features\n",
    "\n",
    "Binary classification for each emotion. Trained with k fold cross validation and a loop over multiple shufflings of the data. \n",
    "Balances data to account for imbalanced data (some emotions are not reported as often as others)\n",
    "\n",
    "Now we do not take the mean or median over the features but we perform classification on all data and then do a majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c10ab61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2c60689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "\n",
    "ZC = np.load('../preprocessing/zeroCrossings_frame100ms_hop50ms.npy')\n",
    "SC = np.load('../preprocessing/spectralCentroid_frame100ms_hop50ms.npy')\n",
    "SV = np.load('../preprocessing/spectralVariance_frame5000ms_hop2500ms.npy')\n",
    "ST = np.load('../preprocessing/staticTempoLibrosa.npy')\n",
    "\n",
    "labels = pd.read_csv('../preprocessing/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "829994fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the emotion labels \n",
    "# These correspond to the average number each specific emotion was reported\n",
    "\n",
    "# For classifying we threshold these averages at 0.5. \n",
    "# Average > 0.5: this emotion corresponds to this song\n",
    "# Average < 0.5: emotion does not belong to this song\n",
    "\n",
    "labels = labels.drop(['genre',\n",
    "             'var_amazement',\n",
    "             'var_solemnity',\n",
    "             'var_tenderness',\n",
    "             'var_nostalgia',\n",
    "             'var_calmness',\n",
    "             'var_power',\n",
    "             'var_joyful_activation',\n",
    "             'var_tension',\n",
    "             'var_sadness',\n",
    "             'mood',\n",
    "             'var_mood',\n",
    "             'liked',\n",
    "             'var_liked',\n",
    "             'disliked',\n",
    "             'var_disliked',\n",
    "             'age',\n",
    "             'var_age',\n",
    "             'gender',\n",
    "             'var_gender',\n",
    "             'number_of_observations',\n",
    "             'track id'             \n",
    "            ], axis=1)\n",
    "\n",
    "emotions = list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d685ff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amazement            0.134012\n",
       "solemnity            0.195961\n",
       "tenderness           0.176911\n",
       "nostalgia            0.254279\n",
       "calmness             0.299257\n",
       "power                0.190244\n",
       "joyful_activation    0.261896\n",
       "tension              0.237685\n",
       "sadness              0.185288\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e034864",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc88d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe\n",
    "\n",
    "Ndata_per_song = np.shape(ZC)[1]\n",
    "assert Ndata_per_song != 400\n",
    "[ZC, SC, SV, ST] = StrechArrays([ZC, SC, SV, ST])\n",
    "assert np.shape(ZC) == np.shape(SC) == np.shape(SV) == np.shape(ST)\n",
    "\n",
    "features_dict_medians = {'ZC': ZC.flatten(),\n",
    "                         'SC': SC.flatten(),\n",
    "                         'SV': SV.flatten(),\n",
    "                         'StaticTempo': ST.flatten()}\n",
    "features = pd.DataFrame(data=features_dict_medians)\n",
    "\n",
    "\n",
    "# Remove NaN values\n",
    "labels = pd.DataFrame(labels.loc[labels.index.repeat(Ndata_per_song)])  # repeat to meet the number of features\n",
    "labels = labels.reset_index(drop=True)\n",
    "features, labels = removeNaN(features, labels)\n",
    "assert not features.isnull().any().any(), 'features contains NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a01288",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Doing the actual training of the support vector classifier over multple rounds of shuffeling\n",
    "assert not features.isnull().any().any(), 'features contains NaN1'\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "N_emotions = 9\n",
    "N_features = 4\n",
    "\n",
    "confusion_Matrix = np.zeros((N_emotions, 2, 2))\n",
    "\n",
    "N_shuffles = 1\n",
    "k = 2\n",
    "accuracies = np.zeros((N_emotions, N_shuffles))\n",
    "\n",
    "emotions = ['amazement']\n",
    "\n",
    "assert not features.isnull().any().any(), 'features contains NaN2'\n",
    "\n",
    "for e_idx, emotion in enumerate(emotions):\n",
    "    assert not features.isnull().any().any(), 'features contains NaN3'\n",
    "    \n",
    "    for Siter in range(N_shuffles):\n",
    "        assert not features.isnull().any().any(), 'features contains NaN4'\n",
    "        \n",
    "        thresholdedLabel = copy.deepcopy(labels[emotion])\n",
    "\n",
    "        thresholdedLabel[thresholdedLabel >= threshold] = int(1)\n",
    "        thresholdedLabel[thresholdedLabel < threshold] = int(0)\n",
    "       \n",
    "        assert not features.isnull().any().any(), 'features contains NaN5'\n",
    "        \n",
    "        features, thresholdedLabel = shuffleData(features, thresholdedLabel)\n",
    "        assert not features.isnull().any().any(), 'features contains NaN6'\n",
    "        confusion_Matrix[e_idx, :, :] += kFoldConfusionMatrix(k, features, thresholdedLabel)\n",
    "\n",
    "        accuracies[e_idx, Siter] = np.sum(\n",
    "            np.eye(2)*confusion_Matrix[e_idx, :, :])/np.sum(confusion_Matrix[e_idx, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc1cb03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "for e_idx, emotion in enumerate(emotions):\n",
    "    print(f'EMOTION {emotion}: \\n')\n",
    "    print(f'Accuracy: {np.mean(accuracies[e_idx, :])} +- {np.std(accuracies[e_idx, :])} \\n')\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    CMATRIX = confusion_Matrix[e_idx, :, :]\n",
    "    print(CMATRIX)\n",
    "    print('\\n\\n')\n",
    "    CM = ConfusionMatrixDisplay(CMATRIX)\n",
    "    CM.plot(ax=ax)\n",
    "    ax.set_title(f'{emotion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71553b44",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d4a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StrechArrays(Listofarrays):\n",
    "    \"\"\"\n",
    "    Since we possibly use different window and hop sizes for computing the simple features we have arrays of different size. \n",
    "    For majority vote classification we need data arrays of same length\n",
    "    Since they all correspond to the same time axis, we can 'stretch' the array by repeating values\n",
    "    This function returns 'stretched' arrays with lenght equal to the length of the largest array.\n",
    "    \"\"\"\n",
    "    Nsongs = np.shape(Listofarrays[0])[0]\n",
    "    maxlength = 0\n",
    "    for array in Listofarrays:\n",
    "        if not array.ndim == 1:\n",
    "            maxlength = max(maxlength, np.shape(array)[1])\n",
    "    SOL = []\n",
    "    for array in Listofarrays:\n",
    "        length = np.shape(array)[1] if not array.ndim == 1 else 1\n",
    "        if not length == maxlength:\n",
    "            newarray = np.zeros((Nsongs, maxlength))\n",
    "            for song in range(Nsongs):\n",
    "                arr = []\n",
    "                for i in range(maxlength):\n",
    "                    arr.append(array[song, int(i*length/maxlength)]\n",
    "                               ) if not array.ndim == 1 else arr.append(array[song])\n",
    "                newarray[song, :] = np.array(arr)\n",
    "            assert np.shape(newarray) == (Nsongs, maxlength)\n",
    "            SOL.append(newarray)\n",
    "        else:\n",
    "            assert np.shape(array) == (Nsongs, maxlength)\n",
    "            SOL.append(array)\n",
    "    return SOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46e24d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "\n",
    "def shuffleData(features, labels):\n",
    "#     features = features.reset_index(drop=True)\n",
    "#     labels = labels.reset_index(drop=True)\n",
    "    assert not features.isnull().any().any(), 'features contains NaN111'\n",
    "    n_data = len(features)\n",
    "    idx = np.random.permutation(n_data)\n",
    "    features, labels = features.reindex(idx), labels.reindex(idx)\n",
    "    assert not features.isnull().any().any(), 'features contains NaN11'\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5656a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K fold Crossvalidation\n",
    "\n",
    "def kFoldConfusionMatrix(k, features, labels):\n",
    "    \n",
    "#     assert not features.isnull().any().any(), 'features contains NaN'\n",
    "#     assert not labels.isnull().any().any(), 'labels contains NaN'\n",
    "\n",
    "    kfold_train_metrics = []\n",
    "    kfold_test_metrics = []\n",
    "\n",
    "    confusion_Matrix_total = np.zeros((2, 2), dtype= 'int')\n",
    "\n",
    "    total_input = features\n",
    "    total_labels = labels\n",
    "\n",
    "    cv = KFold(n_splits=k)\n",
    "\n",
    "    for train_index, test_index in cv.split(total_input):        \n",
    "        train_df, train_labels = total_input.iloc[train_index], total_labels.iloc[train_index]\n",
    "        test_df, test_labels = total_input.iloc[test_index], total_labels.iloc[test_index]\n",
    "\n",
    "        # Standardizing data\n",
    "        mean = train_df.mean()\n",
    "        std = train_df.std()\n",
    "\n",
    "        train_df = (train_df - mean) / std\n",
    "        test_df = (test_df - mean) / std\n",
    "\n",
    "        # Classifier\n",
    "        clf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "        clf.fit(train_df, train_labels)\n",
    "\n",
    "        kfold_train_metrics.append(clf.score(train_df, train_labels))\n",
    "        kfold_test_metrics.append(clf.score(test_df, test_labels))\n",
    "\n",
    "        assert np.shape(clf.predict(test_df)) == np.shape(test_labels)\n",
    "        \n",
    "        CM = confusion_matrix(test_labels, clf.predict(test_df), labels= [0,1])\n",
    "        \n",
    "        assert np.shape(CM) == (2,2)\n",
    "\n",
    "        confusion_Matrix_total += CM\n",
    "    return confusion_Matrix_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcdb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNaN(features, labels):\n",
    "    # Look for NaN values in features dataframe and drop these rows and the corresponding rows in label dataframe\n",
    "\n",
    "    NaNidx = np.where(features.isnull().any(axis=1).tolist())[0]\n",
    "\n",
    "    F = features.drop(NaNidx, axis=0)\n",
    "#     labels = pd.DataFrame(labels)\n",
    "    L = labels.drop(NaNidx, axis=0)\n",
    "    features = features.reset_index(drop=True)\n",
    "    labels = labels.reset_index(drop=True)\n",
    "    assert not (F.isnull()).any().any(), 'NaN values in features not removed'\n",
    "    \n",
    "    return F, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1d0ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   357,   2913,   3965,   5108,   5984,   7926,   8535,   9917,\n",
       "        10310,  12459,  19462,  19725,  21487,  23533,  26274,  26627,\n",
       "        27495,  28371,  28380,  28601,  29338,  31120,  31985,  38040,\n",
       "        40250,  44045,  45699,  46155,  49121,  49597,  49811,  51777,\n",
       "        52260,  54099,  57106,  58851,  59265,  61372,  62968,  66739,\n",
       "        66764,  68517,  69194,  69701,  70042,  73620,  75188,  77709,\n",
       "        78872,  79076,  81245,  82214,  82599,  83052,  83793,  86684,\n",
       "        87137,  88120,  88738,  89820,  89990,  92734,  98347,  98412,\n",
       "       101314, 105960, 106556, 110006, 111254, 118891, 119033, 119610,\n",
       "       121669, 123826, 125050, 125727, 126938, 128826, 132865, 135374,\n",
       "       136891, 137190, 146884, 150876, 152019, 152653, 153471, 156349,\n",
       "       157689, 159409, 159452, 160411, 160538, 162161, 163823, 166662,\n",
       "       166909, 167007, 167161, 167499, 168755, 171698, 174136, 176506,\n",
       "       178392, 179323, 180560, 184439, 185038, 189145, 191928, 199400,\n",
       "       199856, 203725, 206408, 206466, 209226, 213075, 215030, 217965,\n",
       "       222079, 222127, 232052, 233657, 233749, 234541, 235210, 235622,\n",
       "       236727, 236753, 242471, 243045, 244427, 248299, 248507, 257329,\n",
       "       258587, 266033, 268016, 269694, 274708, 275154, 275666, 275881,\n",
       "       277883, 278024, 278664, 279047, 279786, 280047, 283553, 288930,\n",
       "       294368, 294651, 298537, 298658, 302040, 302923, 312689, 320103,\n",
       "       321071, 323165, 323792, 324265, 325442, 329761, 334984, 340109,\n",
       "       342465, 348784, 353927, 353986, 356780, 363831, 365118, 370863,\n",
       "       370988, 373289, 374776, 376742, 376928, 381219, 381997, 383433,\n",
       "       384204, 384386, 385227, 392985, 394470, 397484, 398065, 399192,\n",
       "       401197, 401767, 404090, 408182, 409300, 412390, 414984, 415202,\n",
       "       415609, 415931, 416059, 416584, 419171, 420608, 433060, 433785,\n",
       "       434084, 434640, 436896, 437480, 437738, 438260, 439874, 441222,\n",
       "       441593, 443953, 444047, 444635, 448810, 450242, 455991, 457899,\n",
       "       461027, 461461, 461695, 462610, 463527, 464503, 465016, 466129,\n",
       "       466144, 466909, 469780, 474350, 477593, 478898], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(features.isnull().any(axis=1).tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[[62275]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164364b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071fc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:musicInformatics]",
   "language": "python",
   "name": "conda-env-musicInformatics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
